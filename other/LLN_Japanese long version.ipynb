{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what to generate... \n",
    "* add option to have some translations in native language...\n",
    "# website with html, java\n",
    "* toggle \"include\", insert file path --> insert file, host it as a website..\n",
    "### add lisardo csv automatic instructions\n",
    "\n",
    "... a system, where you can check every line, and regenerate if necessary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum words: 30.0\n",
      "Index(['synonyms, hints, definition, explanation, native_language_definition, native_language_explanation'], dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 15 elements, new values have 17 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     61\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(df\u001b[38;5;241m.\u001b[39miloc[:, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m16\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort_phrase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebsite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong_phrase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmachine_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead)\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 15 elements, new values have 17 elements"
     ]
    }
   ],
   "source": [
    "# works with the csv export from the lln website\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import random\n",
    "\n",
    "# chatGPT parameters\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"22API_KEY\")\n",
    "\n",
    "max_tokens = 100\n",
    "max_words = max_tokens * 0.3\n",
    "print(\"maximum words:\", max_words)\n",
    "model = \"gpt-4-1106-preview\" # \"gpt-3.5-turbo-16k # gpt-4-1106-preview # gpt-4-turbo # gpt-4-32k\n",
    "\n",
    "# what should be generated by chatGPT?\n",
    "\n",
    "native_language = \"english\"\n",
    "\n",
    "global include_definition\n",
    "global include_synonyms\n",
    "global include_explanation\n",
    "global include_hint\n",
    "global native_language_include_definition\n",
    "global native_language_include_synonyms\n",
    "global native_language_include_explanation\n",
    "global native_language_include_hint\n",
    "\n",
    "include_definition = False\n",
    "native_language_include_definition = True\n",
    "\n",
    "include_synonyms = False\n",
    "native_language_include_synonyms = True\n",
    "\n",
    "include_hint = False\n",
    "native_language_include_hint = True\n",
    "\n",
    "include_explanation = False\n",
    "native_language_include_explanation = False\n",
    "\n",
    "# Check if the CSV file exists\n",
    "csv_file_path = \"/Users/moritzvitt/Downloads/df_gpt.csv\"\n",
    "if not os.path.exists(csv_file_path):\n",
    "    # Create a new CSV file\n",
    "    with open(csv_file_path, \"w\") as csv_file:\n",
    "        # Write the header row\n",
    "        csv_file.write(\"synonyms, hints, definition, explanation, native_language_definition, native_language_explanation\")\n",
    "\n",
    "df_gpt = pd.read_csv(csv_file_path, delimiter='\\t')\n",
    "\n",
    "print(df_gpt.columns)\n",
    "#building the data frame\n",
    "df = pd.read_csv('/Users/moritzvitt/downloads/anki/items.csv', delimiter='\\t')\n",
    "\n",
    "\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.iloc[:, [1, 7, 11, 12, 13, 14, 15, 16]], axis=1)\n",
    "\n",
    "df.columns = [\"ID\", \"short_phrase\", \"short_translation\", \"word\", \"stem\", \"word_type\", \"word_translation\", \"website\", \"lang\", \"source\", \"date\", \"long_phrase\", \"machine_translation\", \"human_translation\", \"first_jpg\", \"second_jpg\", \"audio\"]\n",
    "\n",
    "print(df.columns)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First of all: SYNONYMS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_synonyms == True: \n",
    "    df['synonyms'] = ''\n",
    "    def findSynonyms(lang, stem, usage):\n",
    "        if lang == \"en\":\n",
    "            language = \"english\"\n",
    "        if lang == \"it\":\n",
    "            language = \"italian\"\n",
    "        if lang == \"fr\":\n",
    "            language = \"french\"\n",
    "        if lang == \"ja\":\n",
    "            language = \"japanese\"\n",
    "            \n",
    "        #if not synonyms:\n",
    "        messages = [        \n",
    "            {\"role\": \"user\", \"content\": f\"Provide me with two synonyms for '{stem}' in {language} that truly match\\\n",
    "            the meaning of '{stem}' in '{usage}'.\\\n",
    "            If there is no synonym, that fits the meaning of '{stem}' in the context of '{usage}', you can provide with a short description of '{stem}' instead.\\\n",
    "            Provide the synonyms always separated with a comma inbetween.\\\n",
    "            Don't repeat '{stem}' or 'synonym: 'at the beginning of your answer and don't put numbers or bullet points before the synonyms you return\\\n",
    "            Use a maximum of {max_words} words for each synonym.\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            #temperature=0.5\n",
    "        )\n",
    "        \n",
    "        synonyms = response.choices[0].message[\"content\"]\n",
    "        print(synonyms) \n",
    "        \n",
    "        return synonyms\n",
    "\n",
    "    df[\"synonyms\"] = df.apply(lambda row: findSynonyms(row[\"lang\"], row[\"stem\"], row[\"long_phrase\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asapissimo    : pronto, immediately\n",
      "Unterlage    : documents, paperwork\n",
      "Brutto    : gross, before taxes\n",
      "verbeamten    : tenure, civil servant status\n",
      "Gehalt    : salary, income\n",
      "merkwürdige    : odd, peculiar\n",
      "inkompetent    : inept, unqualified\n",
      "Turnhalle    : gymnasium, sports hall\n",
      "Kabelbrand    : electrical fire, wire fire\n",
      "Strafanzeige    : criminal complaints, police reports\n",
      "Herzinfarkt    : myocardial infarction, heart attack\n",
      "fahl    : pallid, lackluster\n",
      "kratzen    : scratch, itch\n",
      "Faust    : fist, clenched hand\n",
      "beeilen    : hurry, hasten\n",
      "begeben    : proceed, move\n",
      "Glühbirnen    : incandescent bulbs, light bulbs\n",
      "Mistviecher    : brats, pests\n",
      "bescheuert    : ridiculous, absurd\n",
      "Schlankheitsfarm    : weight loss clinic, slimming spa\n",
      "pennen    : crash, sleep over\n",
      "Vorgeschmack    : foretaste, preview\n",
      "schuldest    : owe, are indebted\n",
      "anheben    : raise, hoist\n",
      "verlegen    : install, lay\n",
      "Glitter    : sparkle, shimmer\n",
      "Arschritze    : butt crack, gluteal cleft\n",
      "verarschen    : mock, fool\n",
      "übernimmst    : take over, cover for\n",
      "ernsthaft    : seriously, for real\n",
      "hup    : horn, car horn\n",
      "fresse    : shut up, be quiet\n",
      "Titte    : breast, boob\n",
      "Arsch    : soul, person\n",
      "Schulhof    : schoolyard, playground\n",
      "gucken    : look, watch\n",
      "Stecknadel    : pin, needle\n",
      "Kohle    : cash, dough\n",
      "vergraben    : buried, stashed\n",
      "Gelutsche    : sweet talk, schmoozing\n",
      "heb    : save, keep\n",
      "Freiheit    : liberty, freedom\n",
      "Allgemeinbildung    : general knowledge, general education\n",
      "Farce    : mockery, sham\n",
      "verpiss    : scram, buzz off\n",
      "nenn    : give, tell\n",
      "wiehert    : whinnies, neighs\n",
      "reiten    : horseback riding, equestrianism\n",
      "pimmel    : dick, cock\n",
      "Seitenstechen    : side stitch, side cramp\n",
      "lebensverändernd    : life-changing, transformative\n",
      "beuteschema    : \"type,\" \"taste\"\n",
      "brüsten    : bosom, breasts\n",
      "hosentasche    : pocket, trouser pocket\n",
      "Gesamtwisse    : collective knowledge, total human knowledge\n",
      "verzerren    : distort, warp\n",
      "okay    : fine, all right\n",
      "auch    : too, as well\n",
      "schlecht    : poor, bad\n"
     ]
    }
   ],
   "source": [
    "if native_language_include_synonyms == True: \n",
    "    df['synonyms'] = ''\n",
    "    def native_language_findSynonyms(stem, usage):\n",
    "        #if not synonyms:\n",
    "        messages = [        \n",
    "            {\"role\": \"user\", \"content\": f\"Provide me with two synonyms for '{stem}' in {native_language} that truly match\\\n",
    "            the meaning of '{stem}' in '{usage}'.\\\n",
    "            If there is no synonym, that fits the meaning of '{stem}' in the context of '{usage}', you can provide with a short description of '{stem}' instead.\\\n",
    "            Provide the synonyms always separated with a comma inbetween.\\\n",
    "            Don't repeat '{stem}' or 'synonym: 'at the beginning of your answer and don't put numbers or bullet points before the synonyms you return\\\n",
    "            Use a maximum of {max_words} words for each synonym.\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            #temperature=0.5\n",
    "        )\n",
    "        \n",
    "        synonyms = response.choices[0].message[\"content\"]\n",
    "        print(stem, \"   :\", synonyms) \n",
    "        \n",
    "        return synonyms\n",
    "\n",
    "    df[\"synonyms\"] = df.apply(lambda row: native_language_findSynonyms(row[\"stem\"], row[\"long_phrase\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_hint == True: \n",
    "    df['hint'] = ''\n",
    "    def create_hint(lang, synonyms, word, stem, usage):\n",
    "        length = len(usage.split())\n",
    "        # print(length)\n",
    "        max_tokens = int(150 + length + 0.33 * length)\n",
    "        max_words = 8\n",
    "        if lang == \"en\":\n",
    "        #if not synonyms:\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Provide me with a brief explanation of '{word}'. You can also take in account the context of '{stem}' in '{usage}'.\\\n",
    "                Be very concise, use a maximum of {max_words} words!\\\n",
    "                Return the explanation in the form '{word}: explanation.'.\"}\n",
    "            ]\n",
    "\n",
    "        if lang == \"fr\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fournissez-moi une brève explication de {word}'\\\n",
    "                Vous pouvez également tenir compte du contexte de '{stem}' dans '{usage}'.\\\n",
    "                Soyez très concis, utilisez un maximum de {max_words} mots ! Je veux que l'explication soit différente de '{synonyms}'.\\\n",
    "                Renvoyez l'explication sous la forme '{word} : explication.\"}\n",
    "            ]\n",
    "\n",
    "        if lang == \"it\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fornisci una breve spiegazione di '{word}'.\\\n",
    "                Si può anche prendere in considerazione il contesto di '{stem}' in '{usage}'.\\\n",
    "                Siate molto concisi, usare un massimo di {max_words} parole!\\\n",
    "                Restituire la spiegazione nella forma '{word}: spiegazione.'\"}\n",
    "            ]\n",
    "\n",
    "        if lang == \"ja\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"'{word}'の簡単な説明を提供してください。また、'{usage}'における'{stem}'の文脈を考慮することもできます。\\\n",
    "                非常に簡潔に表現し、最大で{max_words}単語を使用してください。\\\n",
    "                説明は'{word}：説明。'の形式で提供してください.\"}\n",
    "            ]\n",
    "            \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            #temperature=0.5\n",
    "        )\n",
    "        \n",
    "        hint = response.choices[0].message[\"content\"]\n",
    "        print(hint) \n",
    "        \n",
    "        return hint\n",
    "\n",
    "    df[\"hint\"] = df.apply(lambda row: create_hint(row[\"lang\"], row[\"synonyms\"], row[\"word\"], row[\"stem\"], row[\"long_phrase\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# native Language hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asapissimo: extremely urgent, ASAP intensified.\n",
      "Unterlagen: Documents required, to be submitted later.\n",
      "Brutto: Gross amount before deductions like taxes.\n",
      "verbeamtet: granted civil servant status.\n",
      "Gehalt: Usually means \"salary\" in German.\n",
      "Merkwürdige: \"Strange\" or \"peculiar\" in context.\n",
      "inkompetent: lacking necessary skills or knowledge.\n",
      "Turnhalle: Sports or gymnasium hall.\n",
      "Kabelbrand: electrical cable fire or malfunction.\n",
      "Strafanzeigen: formal criminal complaints or reports.\n",
      "Herzinfarkt: German for heart attack.\n",
      "fahlen: having a pallid, negative connotation.\n",
      "kratzen: German for 'scratch'.\n",
      "Faust: A symbol for force or violent threat.\n",
      "beeilt: imperative of 'hurry up'.\n",
      "begeben: to proceed, go to a place.\n",
      "Glühbirnen: German for lightbulbs, electric bulbs for illumination.\n",
      "Mistviecher: colloquial, derogatory for animals/pests.\n",
      "bescheuert: foolish or senseless.\n",
      "Schlankheitsfarm: weight loss retreat or slimming spa.\n",
      "pennen: German slang for sleeping or crashing.\n",
      "Vorgeschmack: A small preview or taste of something.\n",
      "schuldest: you owe (used in debt context).\n",
      "anheben: to lift or raise something.\n",
      "verlegen: to install, e.g., pipes.\n",
      "Glitter: Sparkling decorative particles, hard to clean off.\n",
      "Arschritze: German for \"butt crack.\".\n",
      "verarschen: German for \"to mock\" or \"to tease\".\n",
      "Übernimmst: German for \"Are you taking over\".\n",
      "Ernsthaft: Seriously; expression of disbelief or earnest inquiry.\n",
      "Hupe: colloquial for car horn.\n",
      "Fresse: colloquial for \"shut up\" or \"be quiet.\"\n",
      "Titten: German colloquial term for breasts.\n",
      "Arsch: German slang for \"nobody\" (in given context).\n",
      "Schulhof: German for schoolyard or school courtyard.\n",
      "guckt: colloquial German for \"looks\" or \"watches\".\n",
      "Stecknadel: Pin or marker (probably on a map).\n",
      "Kohle: Slang for \"money\" in German.\n",
      "vergraben: buried (money or object) for safekeeping.\n",
      "Gelutsche: meaningless or annoying talk, sweet-talking.\n",
      "heb: imperative of 'heben', meaning 'save' or 'keep'.\n",
      "Freiheit: German for \"freedom\" or \"liberty\".\n",
      "Allgemeinbildung: General knowledge or education.\n",
      "Farce: Mockery or sham, lacking serious intent.\n",
      "Verpiss: German slang for \"go away.\"\n",
      "Nenn: Command form of 'to name.'\n",
      "wiehert: sound of horse neighing.\n",
      "reiten: to ride, typically a horse.\n",
      "Pimmel: German slang for penis.\n",
      "Seitenstechen: Side stitch, sharp pain in torso.\n",
      "Lebensverändernde: life-changing experiences.\n",
      "Beuteschema: Preferred partner characteristics.\n",
      "Brüsten: Likely refers to breasts (informal, possibly pejorative).\n",
      "Hosentasche: Pocket of trousers/pants.\n",
      "Gesamtwissen: collective human knowledge, accessible via technology.\n",
      "verzerrt: sound is distorted or altered.\n",
      "okay: Inquiry about well-being or situation.\n",
      "auch: also, too, as well.\n",
      "schlecht: poor quality, not good.\n"
     ]
    }
   ],
   "source": [
    "if native_language_include_hint == True: \n",
    "    df['hint'] = ''\n",
    "    def create_hint(synonyms, word, stem, usage):\n",
    "        length = len(usage.split())\n",
    "        # print(length)\n",
    "        max_tokens = int(150 + length + 0.33 * length)\n",
    "        max_words = 8\n",
    "        if native_language == \"english\":\n",
    "        #if not synonyms:\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Provide me with a brief explanation of '{word}'. You can also take in account the context of '{stem}' in '{usage}'.\\\n",
    "                Be very concise, use a maximum of {max_words} words!\\\n",
    "                Return the explanation in the form '{word}: explanation.'.\"}\n",
    "            ]\n",
    "        \n",
    "        if native_language == \"turkish\":\n",
    "        #if not synonyms:\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"'{word}' kelimesinin kısa bir açıklamasını sağla. \\\n",
    "                    Ayrıca, '{usage}' içinde '{stem}' bağlamını da dikkate alabilirsin. \\\n",
    "                    Çok özlü ol, en fazla {max_words} kelime kullan!\\\n",
    "                    Açıklamayı '{word}: açıklama.' şeklinde döndür.\"}\n",
    "            ]\n",
    "\n",
    "        if native_language == \"french\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fournissez-moi une brève explication de {word}'\\\n",
    "                Vous pouvez également tenir compte du contexte de '{stem}' dans '{usage}'.\\\n",
    "                Soyez très concis, utilisez un maximum de {max_words} mots ! Je veux que l'explication soit différente de '{synonyms}'.\\\n",
    "                Renvoyez l'explication sous la forme '{word} : explication.\"}\n",
    "            ]\n",
    "\n",
    "        if native_language == \"italian\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fornisci una breve spiegazione di '{word}'.\\\n",
    "                Si può anche prendere in considerazione il contesto di '{stem}' in '{usage}'.\\\n",
    "                Siate molto concisi, usare un massimo di {max_words} parole!\\\n",
    "                Restituire la spiegazione nella forma '{word}: spiegazione.'\"}\n",
    "            ]\n",
    "\n",
    "        if native_language == \"japanese\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"'{word}'の簡単な説明を提供してください。また、'{usage}'における'{stem}'の文脈を考慮することもできます。\\\n",
    "                非常に簡潔に表現し、最大で{max_words}単語を使用してください。\\\n",
    "                説明は'{word}：説明。'の形式で提供してください.\"}\n",
    "            ]\n",
    "            \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            #temperature=0.5\n",
    "        )\n",
    "        \n",
    "        hint = response.choices[0].message[\"content\"]\n",
    "        print(hint) \n",
    "        \n",
    "        return hint\n",
    "\n",
    "    df[\"hint\"] = df.apply(lambda row: create_hint(row[\"synonyms\"], row[\"word\"], row[\"stem\"], row[\"long_phrase\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# include definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_definition == True: \n",
    "    df['definition'] = ''\n",
    "    def create_definition(lang, word, stem, usage):\n",
    "        length = len(usage.split())\n",
    "        # print(length)\n",
    "        max_tokens = int(150 + length + 0.33 * length)\n",
    "        max_words = 15\n",
    "        if lang == \"en\":\n",
    "        #if not synonyms:\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Provide me with a dictionary like definition of '{word}'. You can also take in account the context of '{stem}' in '{usage}'.\\\n",
    "                Be very concise, use a maximum of {max_words} words!\\\n",
    "                Return the definition in the form '{word}: your definition.'.\"}\n",
    "            ]\n",
    "\n",
    "        if lang == \"fr\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fournissez-moi une brève définition de '{word}' semblable à celle d'un dictionnaire.\\\n",
    "                Vous pouvez également tenir compte du contexte de '{stem}' dans '{usage}'.\\\n",
    "                Soyez très concis, utilisez un maximum de {max_words} mots !\\\n",
    "                Renvoyez la définition sous la forme '{word} : votre définition.\"}\n",
    "            ]\n",
    "\n",
    "        if lang == \"it\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fornite una breve definizione da dizionario di '{word}' .\\\n",
    "                Si può anche prendere in considerazione il contesto di '{stem}' in '{usage}'.\\\n",
    "                Siate molto concisi, usare un massimo di {max_words} parole!\\\n",
    "                Restituire la definizione nella forma '{word}: la vostra definizione.'\"}\n",
    "            ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            #temperature=0.5\n",
    "        )\n",
    "        \n",
    "        hint = response.choices[0].message[\"content\"]\n",
    "        print(hint) \n",
    "        \n",
    "        return hint\n",
    "\n",
    "    df[\"definition\"] = df.apply(lambda row: create_definition(row[\"lang\"], row[\"word\"], row[\"stem\"], row[\"long_phrase\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# native_language definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asapissimo: Extremely informal, exaggerated version of \"as soon as possible,\" implying utmost urgency.\n",
      "Unterlagen: documents or paperwork required for a specific process or transaction.\n",
      "Brutto: Total income before deductions such as taxes and social security contributions.\n",
      "verbeamtet: holding the status of a civil servant, typically with employment benefits and job security.\n",
      "Gehalt: 1. Content, substance. 2. Salary, wages. (Context suggests the playful use of ambiguity.)\n",
      "Merkwürdige: adjective, meaning strange, odd, or peculiar in the given context.\n",
      "inkompetent: lacking the necessary skills or knowledge to perform effectively; unqualified.\n",
      "Turnhalle: Gymnasium or sports hall, often part of a school or community center.\n",
      "Kabelbrand: Electrical cable fire caused by short-circuiting or overheating.\n",
      "Strafanzeigen: Formal reports of criminal activities filed to the authorities.\n",
      "Herzinfarkt: Sudden blockage in coronary artery, causing heart muscle damage or death; myocardial infarction.\n",
      "fahlen: not possessing intensity; pallid or lacking in color or vitality.\n",
      "kratzen: to scratch or scrape, often causing an itch or irritation.\n",
      "Faust: Fist in German; context implies threat of violent insertion as punishment for tattling.\n",
      "beeilt: imperative form of \"beeilen\", meaning \"hurry up\" or \"make haste\".\n",
      "begeben: to proceed to, move toward or enter a place for safety or refuge.\n",
      "Glühbirnen: electric bulbs used for producing light, commonly replaceable by a maintenance person or homeowner.\n",
      "Mistviecher: German, derogatory for bothersome animals or figuratively, annoying persons/issues.\n",
      "bescheuert: foolish, stupid, or senseless.\n",
      "Schlankheitsfarm: A facility focused on weight loss, often offering dietary and fitness programs.\n",
      "pennen: (informal, German) to sleep, crash, or stay temporarily at a place.\n",
      "Vorgeschmack: A small preview or taste of what is to come.\n",
      "schuldest: second person singular present of \"schulden,\" meaning owe or are indebted for.\n",
      "anheben: to lift or raise something; to increase or boost a value or amount.\n",
      "verlegen: to install or lay down, as in pipelines or cables.\n",
      "Glitter: Small, shiny particles for decoration, often lingering on skin and clothes.\n",
      "Arschritze: (German, vulgar) the crease or cleft between the buttocks; butt crack.\n",
      "verarschen: to mock, deceive, or make a fool of someone, often in a disrespectful way.\n",
      "Übernimmst: (verb) You take over; assume responsibility or control of something.\n",
      "Ernsthaft: Seriously; used to express genuine curiosity or disbelief.\n",
      "Hupe: (n., colloq.) car horn; slang for breast in certain contexts.\n",
      "Fresse: colloquial, impolite for mouth, often used to tell someone to be quiet or shut up.\n",
      "Titten: Colloquial German for breasts, often considered vulgar.\n",
      "Arsch: (German, slang) buttocks; used pejoratively to mean 'nobody' or 'no one' in colloquial contexts.\n",
      "Schulhof: area of a school's outdoor grounds, typically where students gather for recreation.\n",
      "guckt: (verb) informal German for \"looks\" or \"watches\", third person singular present of \"gucken\".\n",
      "Stecknadel: a pin often used as a marker on maps; figurative for precise location.\n",
      "Kohle: (colloquial, German) money, cash.\n",
      "vergraben: to bury something in the ground for concealment or safekeeping.\n",
      "Gelutsche: unnecessary, often insincere sweet talk or flattery, typically to manipulate or delay.\n",
      "heb: Informal, imperative form of \"heben\", German for \"lift\", \"keep\", or \"save\".\n",
      "Freiheit: The state of being free; absence of constraints; liberty.\n",
      "Allgemeinbildung: Broad general knowledge considered essential for informed social participation.\n",
      "Farce: a mockery, sham event lacking seriousness or value.\n",
      "Verpiss: German slang for \"get lost\" or \"go away,\" used as a dismissive command.\n",
      "Nenn: imperative form of \"nennen,\" meaning \"to name\" or \"to call out\".\n",
      "wiehert: (of a horse) emits a whinny or neighing sound.\n",
      "reiten: to ride a horse or engage in horseback riding.\n",
      "Pimmel: German slang for male genitalia, often considered vulgar.\n",
      "Seitenstechen: Transient sharp pain in the side, often experienced during vigorous exercise.\n",
      "Lebensverändernde: Experiences or events that significantly alter one's life.\n",
      "Beuteschema: Preferred type of partner or person of interest, typically in a romantic context.\n",
      "Brüsten: Colloquially, boasting or referring to prominent breasts in an informal context.\n",
      "Hosentasche: pocket in trousers for carrying small items, e.g., smartphone with internet access.\n",
      "Gesamtwissen: Total collective knowledge accessible, especially via technology.\n",
      "verzerrt: distorted, altered from original form, typically in a way that sounds unclear or unnatural.\n",
      "okay: Everything is satisfactory or acceptable; no problems or concerns.\n",
      "auch: also, as well, too, even (used to indicate inclusion or addition).\n",
      "schlecht: adverb or adjective; poor quality, bad, or unfavorable; here, referring to poor connection.\n"
     ]
    }
   ],
   "source": [
    "if native_language_include_definition == True: \n",
    "    df['definition'] = ''\n",
    "    def create_definition(word, stem, usage, word_type):\n",
    "        length = len(usage.split())\n",
    "        # print(length)\n",
    "        max_tokens = int(150 + length + 0.33 * length)\n",
    "        max_words = 15\n",
    "        if native_language == \"english\":\n",
    "        #if not synonyms:\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Provide me with a dictionary like definition of '{word}'. You can also take in account the context of '{stem}' in '{usage}'.\\\n",
    "                Be very concise, use a maximum of {max_words} words!\\\n",
    "                Return the definition in the form '{word}: your definition.'.\"}\n",
    "            ]\n",
    "\n",
    "        if native_language == \"turkish\":\n",
    "            # instruction = \"\"\n",
    "            # # if word_type == \"Noun\":\n",
    "            # #     instruction = \"\"\n",
    "            # # if word_type == \"Adj\":\n",
    "            # if word_type == \"Verb\":\n",
    "            #     instruction = \"(sonsuz kip)\"\n",
    "        #if not synonyms:\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"'{word}' için sözlük tarzında bir tanım sağla. \\\n",
    "                    Ayrıca, '{usage}' içinde '{stem}' bağlamını da dikkate alabilirsin. \\\n",
    "                    Çok özlü ol, en fazla {max_words} kelime kullan!\\\n",
    "                    Tanımı '{word}: tanımınız.' şeklinde döndür.\"}\n",
    "            ]\n",
    "\n",
    "        if native_language == \"french\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fournissez-moi une brève définition de '{word}' semblable à celle d'un dictionnaire.\\\n",
    "                Vous pouvez également tenir compte du contexte de '{stem}' dans '{usage}'.\\\n",
    "                Soyez très concis, utilisez un maximum de {max_words} mots !\\\n",
    "                Renvoyez la définition sous la forme '{word} : votre définition.\"}\n",
    "            ]\n",
    "\n",
    "        if native_language == \"italian\": \n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": \n",
    "                f\"Fornite una breve definizione da dizionario di '{word}' .\\\n",
    "                Si può anche prendere in considerazione il contesto di '{stem}' in '{usage}'.\\\n",
    "                Siate molto concisi, usare un massimo di {max_words} parole!\\\n",
    "                Restituire la definizione nella forma '{word}: la vostra definizione.'\"}\n",
    "            ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            #temperature=0.5\n",
    "        )\n",
    "        \n",
    "        hint = response.choices[0].message[\"content\"]\n",
    "        print(hint) \n",
    "        \n",
    "        return hint\n",
    "\n",
    "    df[\"definition\"] = df.apply(lambda row: create_definition(row[\"word\"], row[\"stem\"], row[\"long_phrase\"], row[\"word_type\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createID(ID, source, date):\n",
    "    newID = f\"{ID}{source}{date}\"\n",
    "    newID = newID.replace(\" \", \"__\")\n",
    "    return newID\n",
    "df[\"ID\"] = df.apply(lambda row: createID(row[\"ID\"], row[\"source\"], row[\"date\"]), axis=1)\n",
    "\n",
    "def mp3_pattern(mp3):\n",
    "        mp3 = \"[sound:\" + mp3 + \"]\"\n",
    "        return mp3\n",
    "df[\"audio\"] = df.apply(lambda row: mp3_pattern(row[\"audio\"]), axis=1)\n",
    "\n",
    "def image(first_jpg, second_jpg):\n",
    "    image = f'<img src=\"{first_jpg}\"><img src=\"{second_jpg}\">'\n",
    "    return image\n",
    "df[\"first_jpg\"] = df.apply(lambda row: image(row[\"first_jpg\"], row[\"second_jpg\"]), axis=1)\n",
    "\n",
    "# def clozePattern(word, phrase, translations):\n",
    "#         word_new = f\"{{c1::{word}::{translations}}}\"\n",
    "#         word_new = str(word_new)\n",
    "#         #print(word_new)\n",
    "#         phrase = phrase.replace(word, word_new)\n",
    "#         return phrase\n",
    "#         print(phrase)\n",
    "# df[\"long_phrase\"] = df.apply(lambda row: clozePattern(row[\"word\"], row[\"long_phrase\"], row[\"synonyms\"]), axis=1)\n",
    "\n",
    "import re\n",
    "\n",
    "def clozePattern(word, phrase, translations):\n",
    "    word_new = f\"{{{{c1::{word}::{translations}}}}}\"\n",
    "    phrase = re.sub(rf'\\b{word}\\b', word_new, phrase, flags=re.IGNORECASE)\n",
    "    return phrase\n",
    "\n",
    "df[\"long_phrase\"] = df.apply(lambda row: clozePattern(row[\"word\"], row[\"long_phrase\"], row[\"synonyms\"]), axis=1)\n",
    "\n",
    "def cleanHint(hint):\n",
    "    # print(type(hint))\n",
    "    if hint != \"\" and \":\" in hint:\n",
    "        parts = re.findall(r\"[:](.+)?\", hint) \n",
    "        # r\"[:](.+)?\" worked\n",
    "        return f\": {parts[0]}\"\n",
    "    else: \n",
    "        return \"\"\n",
    "df[\"hint\"] = df[\"hint\"].apply(cleanHint)\n",
    "\n",
    "# def definition_field(definition):\n",
    "#       newDefinition = definition\n",
    "#       return newDefinition\n",
    "# df[\"definition\"] = df.apply(lambda row: definition_field(row[\"word_translation\"]), axis=1)\n",
    "\n",
    "def notes_field(translation, word_translation):\n",
    "    translation_str = str(translation) if not pd.isnull(translation) else \"\"\n",
    "    word_translation_str = str(word_translation) if not pd.isnull(word_translation) else \"\"\n",
    "    newNotes = translation_str + word_translation_str\n",
    "    return newNotes\n",
    "\n",
    "df[\"notes\"] = df.apply(lambda row: notes_field(row[\"human_translation\"], row[\"word_translation\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ankiOut=df[['ID', 'long_phrase', 'hint', 'definition', 'first_jpg', 'audio', 'synonyms', 'notes']].copy()\n",
    "ankiOut.columns = ['ID', 'cloze', 'hint', 'definition', 'image', 'audio', 'synonyms', 'notes']\n",
    "# ankiOut.to_csv(\"/Users/moritzvitt/coding/anki.csv\", sep=';', index=False, header=False)\n",
    "ankiOut.to_csv(\"/Users/moritzvitt/coding/anki.csv\", sep='\\t', index=False)\n",
    "\n",
    "\n",
    "df.to_excel(\"/Users/moritzvitt/coding/df.xlsx\", index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf534235b0e1999e3af5c54f86d8a2ac9180cea7dad527405cf1d5b9e4c682f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
