{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WORDS',), ('LOOKUPS',), ('BOOK_INFO',), ('DICT_INFO',), ('METADATA',), ('VERSION',)]\n",
      "Table: WORDS\n",
      "id\n",
      "word\n",
      "stem\n",
      "lang\n",
      "category\n",
      "timestamp\n",
      "profileid\n",
      "\n",
      "\n",
      "Table: LOOKUPS\n",
      "id\n",
      "word_key\n",
      "book_key\n",
      "dict_key\n",
      "pos\n",
      "usage\n",
      "timestamp\n",
      "\n",
      "\n",
      "Table: BOOK_INFO\n",
      "id\n",
      "asin\n",
      "guid\n",
      "lang\n",
      "title\n",
      "authors\n",
      "\n",
      "\n",
      "Table: DICT_INFO\n",
      "id\n",
      "asin\n",
      "langin\n",
      "langout\n",
      "\n",
      "\n",
      "Table: METADATA\n",
      "id\n",
      "dsname\n",
      "sscnt\n",
      "profileid\n",
      "\n",
      "\n",
      "Table: VERSION\n",
      "id\n",
      "dsname\n",
      "value\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "database disk image is malformed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/moritzvitt/coding/vocabFromKindle.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/moritzvitt/coding/vocabFromKindle.ipynb#W0sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m cursor \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcursor()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/moritzvitt/coding/vocabFromKindle.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m df_words \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_sql_query(\u001b[39m\"\u001b[39m\u001b[39mSELECT word, stem FROM WORDS;\u001b[39m\u001b[39m\"\u001b[39m, connection)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/moritzvitt/coding/vocabFromKindle.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m df_usage \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_query(\u001b[39m\"\u001b[39;49m\u001b[39mSELECT word_key, usage, dict_key, book_key FROM LOOKUPS;\u001b[39;49m\u001b[39m\"\u001b[39;49m, connection)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/moritzvitt/coding/vocabFromKindle.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m df_books \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_sql_query(\u001b[39m\"\u001b[39m\u001b[39mSELECT id, lang, authors, title FROM BOOK_INFO;\u001b[39m\u001b[39m\"\u001b[39m, connection)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/moritzvitt/coding/vocabFromKindle.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Empty the 'words' and 'lookups' tables\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/moritzvitt/coding/vocabFromKindle.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# This will delete all of the data in the tables permanently!\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/io/sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39massert\u001b[39;00m dtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default\n\u001b[1;32m    485\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    487\u001b[0m         sql,\n\u001b[1;32m    488\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    489\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    490\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    491\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    492\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    493\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    494\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    495\u001b[0m     )\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/io/sql.py:2345\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_iterator(\n\u001b[1;32m   2335\u001b[0m         cursor,\n\u001b[1;32m   2336\u001b[0m         chunksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   2343\u001b[0m     )\n\u001b[1;32m   2344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetchall_as_list(cursor)\n\u001b[1;32m   2346\u001b[0m     cursor\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   2348\u001b[0m     frame \u001b[39m=\u001b[39m _wrap_result(\n\u001b[1;32m   2349\u001b[0m         data,\n\u001b[1;32m   2350\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   2356\u001b[0m     )\n",
      "File \u001b[0;32m~/coding/.venv/lib/python3.9/site-packages/pandas/io/sql.py:2360\u001b[0m, in \u001b[0;36mSQLiteDatabase._fetchall_as_list\u001b[0;34m(self, cur)\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetchall_as_list\u001b[39m(\u001b[39mself\u001b[39m, cur):\n\u001b[0;32m-> 2360\u001b[0m     result \u001b[39m=\u001b[39m cur\u001b[39m.\u001b[39;49mfetchall()\n\u001b[1;32m   2361\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   2362\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(result)\n",
      "\u001b[0;31mDatabaseError\u001b[0m: database disk image is malformed"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re \n",
    "from datetime import datetime\n",
    "import os  # Import the os module\n",
    "\n",
    "# Specify the full path to the database file for the Kindle Vocabulary Builder \n",
    "db_file_path = \"/Volumes/Kindle/system/vocabulary/vocab.db\"\n",
    "\n",
    "connection = sqlite3.connect(db_file_path)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(tables)\n",
    "\n",
    "for table in tables:\n",
    "    cursor.execute(f\"SELECT * FROM {table[0]} LIMIT 1;\")\n",
    "    columns = cursor.description\n",
    "    print(f\"Table: {table[0]}\")\n",
    "    for column in columns:\n",
    "        print(column[0])\n",
    "    print('\\n')\n",
    "\n",
    "connection.close()\n",
    "\n",
    "df_words = pd.DataFrame()\n",
    "df_usage = pd.DataFrame()\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "with sqlite3.connect('/Volumes/Kindle/system/vocabulary/vocab.db') as connection:\n",
    "    cursor = connection.cursor()\n",
    "    df_words = pd.read_sql_query(\"SELECT word, stem FROM WORDS;\", connection)\n",
    "    df_usage = pd.read_sql_query(\"SELECT word_key, usage, dict_key, book_key FROM LOOKUPS;\", connection)\n",
    "    df_books = pd.read_sql_query(\"SELECT id, lang, authors, title FROM BOOK_INFO;\", connection)\n",
    "    # Empty the 'words' and 'lookups' tables\n",
    "    # This will delete all of the data in the tables permanently!\n",
    "    # cursor.execute(\"TRUNCATE TABLE words;\")\n",
    "    # cursor.execute(\"TRUNCATE TABLE lookups;\")\n",
    "    \n",
    "    \n",
    "    # Commit the changes\n",
    "    connection.commit()\n",
    "# Extract and assign the 'word_key' values to the new DataFrame\n",
    "df_usage['word_key'] = df_usage['word_key'].str.extract(r\":(\\w+)\")\n",
    "\n",
    "result = pd.merge(df_usage, df_books, left_on='book_key', right_on='id', how='inner')\n",
    "result = pd.merge(result, df_words, left_on='word_key', right_on='stem', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# Define a function to detect the language of a string\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply the detect_language function to the usage column of the result DataFrame\n",
    "result['lang'] = result['usage'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={'word_key': 'word'})\n",
    "\n",
    "result=result[['stem', 'word', 'usage', 'title', 'authors', 'lang']].copy()\n",
    "result.to_csv('/Users/moritzvitt/Desktop/result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
