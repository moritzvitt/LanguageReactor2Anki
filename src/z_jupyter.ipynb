{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n",
    "from config import column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# IDENTITY and PURPOSE\n",
       "\n",
       "You are a professional language teacher.. Your task is to provide concise, relevant information for sentence-word Anki flashcards, ensuring the student can effectively study vocabulary.\n",
       "\n",
       "# TOOLS\n",
       "\n",
       "You rely mainly on your capability as an LLM to predict the next string of characters. You don't need to analyze the table or anything.\n",
       "\n",
       "# INPUT:\n",
       "\n",
       "You will be given a table of sentence-word pairs from the Google extension 'LanguageReactor', containing the following columns:\n",
       "\n",
       "- 'Word'\n",
       "- 'Context'\n",
       "- 'Context machine translation'\n",
       "- ('Context human translation')\n",
       "\n",
       "The 'Context' column contains a sentence in Spanish, the target language. The 'Word' column contains one word that appears in the 'Context' sentence.\n",
       "\n",
       "# Steps\n",
       "\n",
       "1. ### Clean the data and check for parsing errors\n",
       "\n",
       "Have a look at the table I provided you with. Don't use code for that, just rely on your prediction of characters as LLM.\n",
       "\n",
       "- Remove unnecessary characters and correct weird formatting from 'Word' and 'Context'. However, pay attention that 'Word' always appears in 'Context'.\n",
       "- Check each row to ensure the 'Context' sentence is correctly parsed. The 'Word' should include the entire vocabulary word, not just a fragment. Sometimes parsers may miss the whole verb or expression. Also, check the 'Context machine translation' to see if the 'Word' makes sense in its 'Context'. If there is a parsing error and 'Word' is incomplete, adjust 'Word' to match the vocabulary in 'Context'. Ensure 'Word' is formatted exactly as it appears in 'Context' (including capitalization, grammar, punctuation, and spelling errors if present).\n",
       "\n",
       "2. ### Generate flashcard information\n",
       "\n",
       "   To assist the student, generate a table containing following information for each row:\n",
       "\n",
       "\n",
       "   1. Two or more synonyms for 'Word' based on its 'Context'.\n",
       "   2. Two or more translations for 'Word' based on its 'Context'.\n",
       "   3. A simple 'Example sentence' using 'Word'.\n",
       "   4. The translation of the 'Example sentence'.\n",
       "   5. A brief explanation of 'Word' in its 'Context'.\n",
       "   6. A short explanation of the grammar\n",
       "\n",
       "   When generating this information, stick to the following principles:\n",
       "\n",
       "   - Minimum Information Principle: Formulate the material in the simplest possible way without losing essential information. That means you can safely omit conjunctions like 'or', 'and' and you don't need to say: 現実 means 'reality' or 'actuality'. Instead just say: 現実: reality, actuality.\n",
       "   - Optimize Wording: Ensure the wording is precise and efficient to trigger the correct response quickly.\n",
       "  \n",
       "  The table should contain 7 columns with following column names:\n",
       "   - 'Word'\n",
       "   - 'Context'\n",
       "   - 'Synonyms'\n",
       "   - 'Translations'\n",
       "   - 'Example'\n",
       "   - 'Example translation'\n",
       "   - 'Explanation'\n",
       "\n",
       "\n",
       "# Output\n",
       "\n",
       "Output the generated information as a Markdown table, including the column names as headers.  \n",
       "- Do not include warnings or notes in the output—only the requested sections.\n",
       "- Do not include additional information like 'here is the markdown table' or anything else. The only thing I want is the markdown table.\n",
       "\n",
       "# IDENTITY and PURPOSE\n",
       "\n",
       "You are a professional language teacher, dedicated to helping a student learn a language. Your task is to provide concise, relevant information for sentence-word Anki flashcards, ensuring the student can effectively study vocabulary.\n",
       "\n",
       "# TOOlS\n",
       "\n",
       "You rely mainly on your capability as LLM to predict the next string of characters. You don't need to analyse the table or anything.\n",
       "\n",
       "# INPUT:\n",
       "\n",
       "You will work with a table of sentence-word pairs from the Google extension 'LanguageReactor', containing the following columns:\n",
       "\n",
       "- 'Word'\n",
       "- 'Context'\n",
       "- 'Context machine translation'\n",
       "- ('Context human translation')\n",
       "\n",
       "The 'Context' column contains a sentence in the target language, that the student wants to learn. The 'Word' column contains one word that appears in the 'Context' sentence.\n",
       "\n",
       "# Steps\n",
       "\n",
       "1. ### Clean the data and check for parsing errors\n",
       "\n",
       "   Have a look at the table I provided you with. Don't use code for that, just rely on your prediction of characters as LLM.\n",
       "\n",
       "\n",
       "   - Remove furigana in brackets and correct weird formatting from 'Word' and 'Context'. However, pay attention that 'Word' always appears in 'Context'.\n",
       "   - check each row to ensure the 'Context' sentence is correctly parsed. The 'Word' should include the entire vocabulary word, not just a fragment. Pay particular attention to languages like Japanese, where parsers may miss the whole verb or expression. Also, check the 'Context machine translation' to see if the 'Word' makes sense in its 'Context'. If there is a parsing error and 'Word' is incomplete, adjust 'Word' to match the vocabulary in 'Context'. Ensure 'Word' is formatted exactly as it appears in 'Context' (including capitalization, grammar, punctuation, and spelling errors if present).\n",
       "2. ### Generate flashcard information\n",
       "\n",
       "   To assist the student, generate the following information for each row:\n",
       "\n",
       "\n",
       "   1. Two or more synonyms for 'Word' based on its 'Context'.\n",
       "   2. Two or more translations for 'Word' based on its 'Context'.\n",
       "   3. A simple 'Example sentence' using 'Word'.\n",
       "   4. The translation of the 'Example sentence'.\n",
       "   5. A brief explanation of 'Word' in its 'Context'.\n",
       "   6. A short explanation of the grammar.\n",
       "\n",
       "   When generating this information, stick to the following principles:\n",
       "\n",
       "   1. Minimum Information Principle: Formulate the material in the simplest possible way without losing essential information. Simplicity should not mean skipping difficult parts. That means you can safely leave out conjunctions like 'or', 'and' and you don't need to say: 現実 means 'reality' or 'actuality'. Instead just say: 現実: reality, actuality.\n",
       "   2. Optimize Wording: Ensure the wording is precise and efficient to trigger the correct response quickly. This will reduce errors, increase specificity, reduce response time, and enhance concentration.\n",
       "3. ### FURIGANA for EVERY JAPANESE word! THIS IS EXTREMELY IMPORTANT!\n",
       "\n",
       "   Add furigana in square brackets behind EACH kanji word and add a space before each kanji word The space before each kanji word is EXTREMELY important! Double check, – no – triple check that. Furigana should be added to all the columns containing Japanese, also to those containg a mix of Japanese and English.\n",
       "\n",
       "\n",
       "   - 私[わたし]は 大学生[だいがくせい]です。\n",
       "   - Attention: this would be wrong, as '事', '時間', '代' and '守' lack a blank space before. ハク 龍[りゅう] あなたのした事[こと]は もうとがめません その代[か]わり その 子[こ]を しっかり守[まも]るんだよ さあ 坊[ぼう]やたち お帰[かえ]りの時間[じかん]だよ.\n",
       "   - Same thing here, spaces missing before '代わり' and '行って': 私[わたし]の代[か]わりに行[い]ってください。\n",
       "\n",
       "# EXAMPLES\n",
       "\n",
       "This is how the information you generate should look like:\n",
       "\n",
       "| Word       | Context                                                                                                                                                                 | Machine Translation                                                                                            | Synonyms                       | Translations        | Example sentence                             | Example sentence translation (German) | Explanation                                        |           Grammar explanation           | Additional Notes for chatGPT                                                                      |\n",
       "| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- | ------------------------------ | ------------------- | -------------------------------------------- | ------------------------------------- | -------------------------------------------------- | :-------------------------------------: | ------------------------------------------------------------------------------------------------- |\n",
       "| 子[こ]     | \"ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり 守[まも]るんだよ さあ 坊[ぼう]やたち お 帰[かえ]りの 時間[じかん]だよ\" | \"I won't do what you've done. Instead, we're going to protect that child. Come on, boy, it's time to go home.\" | 子ども[こども]、幼児[ようじ]   | child, kid          | その 子[こ]はかわいいです。                  | Das Kind ist süß.                   | child                                              |  子[こ] means \"child.\" Used as a noun.  | child is a simple word, don't make it complicated. Just give me the translation as 'Explanation'. |\n",
       "| 代[か]わり | \"ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり守るんだよ さあ 坊[ぼう]やたち お 帰[かえ]りの 時間[じかん]だよ\"        | \"I won't do what you've done. Instead, we're going to protect that child. Come on, boy, it's time to go home.\" | 代理[だいり]、替[か]わり       | instead, substitute | 彼[かれ]の 代[か]わりに 行[い]ってください。 | Gehen Sie bitte an seiner Stelle.     | instead, 'instead of doing ...'                    | 代わり means \"instead.\" Used as a noun. |                                                                                                   |\n",
       "| 事[こと]   | \"おばあちゃん ハク生きてた ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり 守[まも]るんだよ\"                            | \"Grandma, Haku was alive. I won't do what you've done. Instead, we're going to protect that child.\"            | 物事[ものごと]、事柄[ことがら] | thing, matter       | その 事[こと]は 難[むずか]しいです。         | Diese Sache ist schwierig.            | action, deed, 'your deeds'                         |   事 means \"thing\" or \"matter.\" Noun.   | '事' is a simple word, don't make it complicated. Just give me the translation as 'Explanation'.  |\n",
       "| 生[い]き   | \"グッドタイミングね おばあちゃん ハク生きてた ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません\"                                                                 | \"Good timing. Grandma, Haku was alive. I won't do what you've done.\"                                           | 生[い]きる、存在[そんざい]する | alive, living       | 彼[かれ]はまだ 生[い]きています。            | Er lebt noch.                         | 生きる: to live, u-verb, 生きて(い)た = was living |      生きる means \"to live.\" Verb.      | This is a verb                                                                                    |\n",
       "| タイミング | \"よかった グッドタイミングね おばあちゃん ハク生きてた\"                                                                                                                 | \"It was good Good timing. Grandma, Haku was alive.\"                                                            | 時期[じき]、機会[きかい]       | timing, opportunity | 今[いま]がいい タイミングです。              | Jetzt ist ein guter Zeitpunkt.        | 'Timing', English loanword                         |    タイミング means \"timing.\" Noun.    | Just give me the translation for the katakana, as this is a woard every english speaker knows     |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n",
    "from config import column_names\n",
    "\n",
    "# load markdown from github repository https://github.com/moritzvitt/moritzProjekt/blob/markdown/system_japanese.md\n",
    "# class BaseAnkiDeckGenerator:\n",
    "#     def __init__(self, df: pd.DataFrame):\n",
    "#         self.ai_input_df = self.df[['short_phrase', 'short_translation', 'word']]\n",
    "\n",
    "\n",
    "\n",
    "    # @log_io\n",
    "\n",
    "def load_markdown():\n",
    "    url1 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/prompts/_general_prompt.md\"\n",
    "    target_language = \"jn\"\n",
    "    examples_url = f\"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/prompts/{target_language}_examples.md\"\n",
    "    url2 = examples_url\n",
    "    # url2 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/add_furigana.md\"\n",
    "    \n",
    "    response1 = requests.get(url1)\n",
    "    markdown1 = response1.text\n",
    "\n",
    "    response2 = requests.get(url2)\n",
    "    markdown2 = response2.text\n",
    "\n",
    "    merged_markdown = markdown1 + \"\\n\" + markdown2\n",
    "    return merged_markdown\n",
    "\n",
    "# load csv from test_dataframes \n",
    "\n",
    "# load dataframe from csv\n",
    "df = pd.read_csv('../test_dataframes/japanese_items/items.csv', delimiter='\\t', encoding='utf-8')\n",
    "# print(df.head())\n",
    "# print(df.shape)\n",
    "\n",
    "# load column_names from config.py\n",
    "df.columns = column_names\n",
    "\n",
    "df = df[[\n",
    "        \"Word\", \n",
    "        \"Context\",\n",
    "        \"Context machine translation\",\n",
    "        \"Context human translation\",\n",
    "        ]]\n",
    "\n",
    "\n",
    "# run \n",
    "def run():\n",
    "    markdown = load_markdown()\n",
    "    display(Markdown(markdown))\n",
    "    # also safe the markdown to a new file\n",
    "    with open(\"final.md\", \"w\") as file:\n",
    "        file.write(markdown+'\\n'+'\\nThis is the table with the word sentence pairs: \\n\\n'+df.to_csv(sep='\\t', encoding='utf-8', index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WORD|胡椒|ja  Word        最後に塩と胡椒で味を整えてください  \\\n",
      "0   WORD|程度|ja  Word              最小限つなぎ程度にして   \n",
      "1  WORD|最小限|ja  Word              最小限つなぎ程度にして   \n",
      "2   WORD|刻む|ja  Word         まずゆで卵を適度に刻んでください   \n",
      "3   WORD|適度|ja  Word         まずゆで卵を適度に刻んでください   \n",
      "4  WORD|さすが|ja  Word  さすがにまだ卵サンドは食べられないみたいだけど   \n",
      "\n",
      "                  Finally, add some salt and pepper.   胡椒 胡椒.1  Noun  \\\n",
      "0  We're going to make sure that we have the leas...   程度   程度  Noun   \n",
      "1  We're going to make sure that we have the leas...  最小限  最小限  Noun   \n",
      "2  First of all, you need to mark the eggs in mod...   刻ん   刻む  Verb   \n",
      "3  First of all, you need to mark the eggs in mod...   適度   適度  Noun   \n",
      "4           I can't seem to eat an egg sandwich yet.  さすが  さすが   Adv   \n",
      "\n",
      "   Unnamed: 7                         pepper, black pepper  Netflix  ...  216  \\\n",
      "0         NaN                       degree, extent, amount  Netflix  ...  215   \n",
      "1         NaN  minimum, minimum limit, minimum requirement  Netflix  ...  215   \n",
      "2         NaN                      carved, engrave, minced  Netflix  ...  212   \n",
      "3         NaN              moderate, appropriate, suitable  Netflix  ...  212   \n",
      "4         NaN       As expected, indeed, Just as I thought  Netflix  ...  211   \n",
      "\n",
      "   80113548  Midnight Diner E7 Episode 7  2024-05-17 15:11  \\\n",
      "0  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "1  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "2  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "3  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "4  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:09   \n",
      "\n",
      "      最小限つなぎ程度にして\\n最後に塩と胡椒で味を整えてください\\nあ まずあの 僕あのこっちで  \\\n",
      "0  ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\\n最小限つなぎ程度にして\\n最...   \n",
      "1  ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\\n最小限つなぎ程度にして\\n最...   \n",
      "2  さすがにまだ卵サンドは食べられないみたいだけど\\nまずゆで卵を適度に刻んでください\\nマヨネ...   \n",
      "3  さすがにまだ卵サンドは食べられないみたいだけど\\nまずゆで卵を適度に刻んでください\\nマヨネ...   \n",
      "4  その後も毎日中島くんは新聞を配っている\\nさすがにまだ卵サンドは食べられないみたいだけど\\n...   \n",
      "\n",
      "   We're going to make sure that we have the least amount of connections.\\nFinally, add some salt and pepper.\\nOh, first of all, I'm over there.  \\\n",
      "0  But if you put too much in it, it tastes like ...                                                                                               \n",
      "1  But if you put too much in it, it tastes like ...                                                                                               \n",
      "2  I can't seem to eat an egg sandwich yet.\\nFirs...                                                                                               \n",
      "3  I can't seem to eat an egg sandwich yet.\\nFirs...                                                                                               \n",
      "4  Ever since then, I've been delivering newspape...                                                                                               \n",
      "\n",
      "  Keep the mayonnaise to a minimum,\\nand add salt and pepper to round out the flavors.\\nMaster. I brought my own bread.  \\\n",
      "0  But don't go overboard with it, or the mayonna...                                                                      \n",
      "1  But don't go overboard with it, or the mayonna...                                                                      \n",
      "2  But he hasn't had egg sandwiches since then.\\n...                                                                      \n",
      "3  But he hasn't had egg sandwiches since then.\\n...                                                                      \n",
      "4  Nakajima still delivers the papers every day.\\...                                                                      \n",
      "\n",
      "   1715958665910_prev.jpg  1715958665910_next.jpg  1715958665910.mp3  \n",
      "0  1715958659411_prev.jpg  1715958659411_next.jpg  1715958659411.mp3  \n",
      "1  1715958656851_prev.jpg  1715958656851_next.jpg  1715958656851.mp3  \n",
      "2  1715958621198_prev.jpg  1715958621198_next.jpg  1715958621198.mp3  \n",
      "3  1715958619583_prev.jpg  1715958619583_next.jpg  1715958619583.mp3  \n",
      "4  1715958582029_prev.jpg  1715958582029_next.jpg  1715958582029.mp3  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "(419, 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n",
    "from config import column_names\n",
    "\n",
    "# Base class for common functionalities\n",
    "class BaseAnkiDeckGenerator:\n",
    "    def __init__(self, csv_path: str, delimiter: str = '\\t', encoding: str = 'utf-8'):\n",
    "        self.df = pd.read_csv(csv_path, delimiter=delimiter, encoding=encoding)\n",
    "        self.df.columns = column_names\n",
    "        self.df = self.df[[\n",
    "            \"Word\", \n",
    "            \"Context\",\n",
    "            \"Context machine translation\",\n",
    "            \"Context human translation\",\n",
    "        ]]\n",
    "        \n",
    "    def display_markdown(self, markdown: str):\n",
    "        display(Markdown(markdown))\n",
    "        \n",
    "    def save_markdown(self, markdown: str, file_name: str = \"final.md\"):\n",
    "        with open(file_name, \"w\") as file:\n",
    "            file.write(markdown + '\\n\\nThis is the table with the word sentence pairs:\\n\\n' + self.df.to_csv(sep='\\t', encoding='utf-8', index=False))\n",
    "\n",
    "\n",
    "# Japanese specific AnkiDeckGe nerator\n",
    "class JapaneseAnkiDeckGenerator(BaseAnkiDeckGenerator):\n",
    "    def __init__(self, csv_path: str):\n",
    "        super().__init__(csv_path)\n",
    "        self.markdown_urls = [\n",
    "            \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/prompts/_general_prompt.md\",\n",
    "            \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/prompts/jn_examples.md\"\n",
    "        ]\n",
    "        \n",
    "    def load_markdown(self):\n",
    "        markdowns = [requests.get(url).text for url in self.markdown_urls]\n",
    "        return \"\\n\".join(markdowns)\n",
    "\n",
    "# Define other language-specific classes similarly if needed\n",
    "# class FrenchAnkiDeckGenerator(BaseAnkiDeckGenerator):\n",
    "#     ...\n",
    "\n",
    "# Run the process\n",
    "def run():\n",
    "    # Path to the Japanese CSV file\n",
    "    csv_path = '../test_dataframes/japanese_items/items.csv'\n",
    "    japanese_generator = JapaneseAnkiDeckGenerator(csv_path)\n",
    "    \n",
    "    markdown = japanese_generator.load_markdown()\n",
    "    japanese_generator.display_markdown(markdown)\n",
    "    japanese_generator.save_markdown(markdown)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choices: [Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='Pros', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Open', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' API', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':\\n\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='1', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Advanced', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Open', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' API', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' uses', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' G', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='PT', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='-', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='3', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' one', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' most', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' advanced', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' language', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' processing', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' models', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' which', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' can', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' generate', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' human', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='-like', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' text', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' based', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' on', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' input', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' it', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' receives', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.\\n\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='2', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Vers', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='atility', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' It', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' can', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' be', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' used', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' wide', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' range', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' applications', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' including', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' drafting', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' emails', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' writing', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' code', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' creating', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' written', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' content', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' answering', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' questions', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' tutoring', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' translating', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' languages', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' sim', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='ulating', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' characters', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' video', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' games', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' much', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' more', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.\\n\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='3', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Easy', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Use', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' The', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' API', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' is', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' designed', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' be', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' simple', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' easy', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' use', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' even', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' for', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' those', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' who', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' are', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' not', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' experts', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' in', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' or', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' machine', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' learning', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.\\n\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='4', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Regular', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Updates', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Open', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' regularly', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' updates', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' its', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' models', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' and', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' API', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' ensuring', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' users', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' have', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' access', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' the', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' latest', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' advancements', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' in', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' technology', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.\\n\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='Cons', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' of', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Open', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='AI', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' API', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':\\n\\n', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='1', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' Cost', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=':', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n",
      "choices: [Choice(delta=ChoiceDelta(content=' The', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n",
      "****************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example of an OpenAI ChatCompletion request with stream=True and stream_options={\"include_usage\": True}\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# a ChatCompletion request\u001b[39;00m\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# stream_options={\"include_usage\": True}, # retrieving token usage for stream response\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43musage: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(f\"{chunk.content}\")\u001b[39;49;00m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/openai/_streaming.py:46\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[0;32m---> 46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/openai/_streaming.py:58\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[1;32m     56\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[0;32m---> 58\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[DONE]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/openai/_streaming.py:50\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter_bytes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_bytes())\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/openai/_streaming.py:280\u001b[0m, in \u001b[0;36mSSEDecoder.iter_bytes\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Split before decoding so splitlines() only uses \\r and \\n\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/openai/_streaming.py:291\u001b[0m, in \u001b[0;36mSSEDecoder._iter_chunks\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[39;00m\n\u001b[1;32m    290\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepends\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    827\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 829\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpx/_models.py:883\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    880\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 883\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpx/_client.py:126\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpx/_transports/default.py:113\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:367\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:363\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:349\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:341\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 341\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:210\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    207\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example of an OpenAI ChatCompletion request with stream=True and stream_options={\"include_usage\": True}\n",
    "\n",
    "# a ChatCompletion request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Can you give me a summary of the pros and cons of the OpenAI API?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    # stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(f\"choices: {chunk.choices}\\nusage: {chunk.usage}\")\n",
    "    # print(f\"{chunk.content}\")\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Moritz is a great guy from Berlin\"},\n",
    "        # {'role': 'assistant', 'content': \"I don't know that\"},\n",
    "        {'role': 'user', 'content': \"who is Moritz?\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "# print the content of the response\n",
    "\n",
    "# for chunk in stream:\n",
    "#     if chunk.choices[0].delta.content is not None:\n",
    "#         print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# List of messages to be sent to the chat completion endpoint\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Always answer briefly. My name is Moritz! What is your name?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Guess where I likely come from, based on my name\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please sum up this dialogue\"},\n",
    "]\n",
    "\n",
    "# Create the chat completion stream\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # Assuming you're using the latest GPT-4 model\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Initialize an empty response container\n",
    "full_response = \"\"\n",
    "\n",
    "# Iterate over the stream and print each chunk\n",
    "for chunk in stream:\n",
    "    if 'choices' in chunk:\n",
    "        delta = chunk['choices'][0]['delta']\n",
    "        if 'content' in delta:\n",
    "            full_response += delta['content']\n",
    "            print(delta['content'], end=\"\")\n",
    "\n",
    "# Optionally, print the full response at the end\n",
    "print(\"\\n\\nFull Response:\\n\", full_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "client = OpenAI()\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create a streaming compion\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Always answer briefly. My name is Moritz! What is your name?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Guess where I likely come from, based on my name\"},\n",
    "            {\"role\": \"user\", \"content\": \"Please sum up this dialogue\"}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Print the streaming response\n",
    "    async for chunk in response:\n",
    "        if 'choices' in chunk:\n",
    "            choice = chunk['choices'][0]\n",
    "            if 'delta' in choice and 'content' in choice['delta']:\n",
    "                print(choice['delta']['content'], end=\"\")\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = Path(\"test_dataframes/italian_items/items_long.csv\")\n",
    "\n",
    "    # Load the csv file\n",
    "df = pd.read_csv(csv_file_path, delimiter='\\t')\n",
    "\n",
    "with open('config/column_names.yaml', 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        column_names = data['column_names']\n",
    "\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "# select the columns word and long_sentence\n",
    "\n",
    "df = df[['word', 'long_phrase']]\n",
    "df.to_csv('test_dataframes/italian_items/items_long_changed.csv', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.animal_type = \"Generic Animal\"\n",
    "\n",
    "    def make_sound(self):\n",
    "        print(f\"{self.animal_type} sound\")\n",
    "\n",
    "class Dog:\n",
    "    def __init__(self):\n",
    "        self.animal_sound = \"Woof!\"\n",
    "        self.animal = Animal()  # Create an Animal instance\n",
    "\n",
    "    def make_sound(self):\n",
    "        self.animal.make_sound()  # Call base class method directly\n",
    "        print(self.animal_sound)\n",
    "\n",
    "# Create objects and call methods\n",
    "animal = Animal()\n",
    "dog = Dog()\n",
    "\n",
    "animal.make_sound()  # Output: Generic Animal sound\n",
    "dog.make_sound()  # Output: Generic Animal sound\n",
    "                #        Woof!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.animal_type = \"Generic Animal\"\n",
    "\n",
    "    def make_sound(self):\n",
    "        print(f\"{self.animal_type} sound\")\n",
    "\n",
    "class Dog(Animal):\n",
    "    def make_sound(self):\n",
    "        self.animal_type = \"Dog\"  # Modify attribute before calling base class method\n",
    "        super().make_sound()\n",
    "        print(\"Woof!\")\n",
    "\n",
    "# Create objects and call methods\n",
    "animal = Animal()\n",
    "dog = Dog()\n",
    "\n",
    "animal.make_sound()  # Output: Generic Animal sound\n",
    "dog.make_sound()  # Output: Dog sound\n",
    "                #        Woof!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Markdown Table Example</title>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked@4.0.12/marked.min.js\"></script>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 40em;\n",
    "        }\n",
    "        table {\n",
    "            width: 50%;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "        }\n",
    "        th {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"markdown-content\"></div>\n",
    "\n",
    "    <script>\n",
    "        const markdownTable = `\n",
    "            | Name   | Age | Occupation   |\n",
    "            |--------|-----|--------------|\n",
    "            | John   | 25  | Engineer     |\n",
    "            | Alice  | 30  | Designer     |\n",
    "            | Bob    | 22  | Developer    |\n",
    "            `;\n",
    "\n",
    "        document.getElementById('markdown-content').innerHTML = marked.parse(markdownTable);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
