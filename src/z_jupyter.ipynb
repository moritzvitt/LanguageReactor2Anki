{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from config import client\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from config import column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Word                                            Context  \\\n",
      "0   程度  ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\\n最小限つなぎ程度にして\\n最...   \n",
      "1  最小限  ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\\n最小限つなぎ程度にして\\n最...   \n",
      "2   刻ん  さすがにまだ卵サンドは食べられないみたいだけど\\nまずゆで卵を適度に刻んでください\\nマヨネ...   \n",
      "3   適度  さすがにまだ卵サンドは食べられないみたいだけど\\nまずゆで卵を適度に刻んでください\\nマヨネ...   \n",
      "4  さすが  その後も毎日中島くんは新聞を配っている\\nさすがにまだ卵サンドは食べられないみたいだけど\\n...   \n",
      "\n",
      "                         Context machine translation  \\\n",
      "0  But if you put too much in it, it tastes like ...   \n",
      "1  But if you put too much in it, it tastes like ...   \n",
      "2  I can't seem to eat an egg sandwich yet.\\nFirs...   \n",
      "3  I can't seem to eat an egg sandwich yet.\\nFirs...   \n",
      "4  Ever since then, I've been delivering newspape...   \n",
      "\n",
      "                           Context human translation  \n",
      "0  But don't go overboard with it, or the mayonna...  \n",
      "1  But don't go overboard with it, or the mayonna...  \n",
      "2  But he hasn't had egg sandwiches since then.\\n...  \n",
      "3  But he hasn't had egg sandwiches since then.\\n...  \n",
      "4  Nakajima still delivers the papers every day.\\...  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# IDENTITY and PURPOSE\n",
       "\n",
       "You are a professional language teacher.. Your task is to provide concise, relevant information for sentence-word Anki flashcards, ensuring the student can effectively study vocabulary.\n",
       "\n",
       "# TOOLS\n",
       "\n",
       "You rely mainly on your capability as an LLM to predict the next string of characters. You don't need to analyze the table or anything.\n",
       "\n",
       "# INPUT:\n",
       "\n",
       "You will be given a table of sentence-word pairs from the Google extension 'LanguageReactor', containing the following columns:\n",
       "\n",
       "- 'Word'\n",
       "- 'Context'\n",
       "- 'Context machine translation'\n",
       "- ('Context human translation')\n",
       "\n",
       "The 'Context' column contains a sentence in Spanish, the target language. The 'Word' column contains one word that appears in the 'Context' sentence.\n",
       "\n",
       "# Steps\n",
       "\n",
       "1. ### Clean the data and check for parsing errors\n",
       "\n",
       "Have a look at the table I provided you with. Don't use code for that, just rely on your prediction of characters as LLM.\n",
       "\n",
       "- Remove unnecessary characters and correct weird formatting from 'Word' and 'Context'. However, pay attention that 'Word' always appears in 'Context'.\n",
       "- Check each row to ensure the 'Context' sentence is correctly parsed. The 'Word' should include the entire vocabulary word, not just a fragment. Sometimes parsers may miss the whole verb or expression. Also, check the 'Context machine translation' to see if the 'Word' makes sense in its 'Context'. If there is a parsing error and 'Word' is incomplete, adjust 'Word' to match the vocabulary in 'Context'. Ensure 'Word' is formatted exactly as it appears in 'Context' (including capitalization, grammar, punctuation, and spelling errors if present).\n",
       "\n",
       "2. ### Generate flashcard information\n",
       "\n",
       "   To assist the student, generate a table containing following information for each row:\n",
       "\n",
       "\n",
       "   1. Two or more synonyms for 'Word' based on its 'Context'.\n",
       "   2. Two or more translations for 'Word' based on its 'Context'.\n",
       "   3. A simple 'Example sentence' using 'Word'.\n",
       "   4. The translation of the 'Example sentence'.\n",
       "   5. A brief explanation of 'Word' in its 'Context'.\n",
       "   6. A short explanation of the grammar\n",
       "\n",
       "   When generating this information, stick to the following principles:\n",
       "\n",
       "   - Minimum Information Principle: Formulate the material in the simplest possible way without losing essential information. That means you can safely omit conjunctions like 'or', 'and' and you don't need to say: 現実 means 'reality' or 'actuality'. Instead just say: 現実: reality, actuality.\n",
       "   - Optimize Wording: Ensure the wording is precise and efficient to trigger the correct response quickly.\n",
       "  \n",
       "  The table should contain 7 columns with following column names:\n",
       "   - 'Word'\n",
       "   - 'Context'\n",
       "   - 'Synonyms'\n",
       "   - 'Translations'\n",
       "   - 'Example'\n",
       "   - 'Example translation'\n",
       "   - 'Explanation'\n",
       "\n",
       "\n",
       "# Output\n",
       "\n",
       "Output the generated information as a Markdown table, including the column names as headers.  \n",
       "- Do not include warnings or notes in the output—only the requested sections.\n",
       "- Do not include additional information like 'here is the markdown table' or anything else. The only thing I want is the markdown table.\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load markdown from github repository https://github.com/moritzvitt/moritzProjekt/blob/markdown/system_japanese.md\n",
    "# class BaseAnkiDeckGenerator:\n",
    "#     def __init__(self, df: pd.DataFrame):\n",
    "#         self.ai_input_df = self.df[['short_phrase', 'short_translation', 'word']]\n",
    "\n",
    "\n",
    "    # @log_io\n",
    "\n",
    "def load_markdown():\n",
    "    url1 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/_general_prompt.md\"\n",
    "    url2 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/jn_examples.md\"\n",
    "    # url2 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/add_furigana.md\"\n",
    "    \n",
    "    response1 = requests.get(url1)\n",
    "    markdown1 = response1.text\n",
    "\n",
    "    response2 = requests.get(url2)\n",
    "    markdown2 = response2.text\n",
    "\n",
    "    merged_markdown = markdown1 + \"\\n\" + markdown2\n",
    "    return merged_markdown\n",
    "\n",
    "# load csv from test_dataframes \n",
    "\n",
    "# load dataframe from csv\n",
    "df = pd.read_csv('../test_dataframes/japanese_items/short_items.csv', delimiter='\\t', encoding='utf-8')\n",
    "print(df.head())\n",
    "# print(df.shape)\n",
    "# # load column_names from config.py\n",
    "# df.columns = column_names\n",
    "\n",
    "# dfa = df[[\n",
    "#         \"Word\", \n",
    "#         \"Context\",\n",
    "#         \"Context machine translation\",\n",
    "#         \"Context human translation\",\n",
    "#         ]]\n",
    "\n",
    "# # select only the first 10 rows\n",
    "# dfa = dfa.head(10)\n",
    "# # dfa to csv\n",
    "# dfa.to_csv('../test_dataframes/japanese_items/short_items.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "    \n",
    "# df = df.to_csv('../test_dataframes/japanese_items/short_items.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "\n",
    "# run \n",
    "def run():\n",
    "    markdown = load_markdown()\n",
    "    display(Markdown(markdown))\n",
    "    # also safe the markdown to a new file\n",
    "    with open(\"final_prompt.md\", \"w\") as file:\n",
    "        file.write(markdown + '\\n' + df.to_csv(sep='\\t', encoding='utf-8', index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe from csv\n",
    "df = pd.read_csv('../test_dataframes/japanese_items/items.csv', delimiter='\\t', encoding='utf-8')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "# load column_names from config.py\n",
    "df.columns = column_names\n",
    "\n",
    "dfa = df[[\n",
    "        \"Word\", \n",
    "        \"Context\",\n",
    "        \"Context machine translation\",\n",
    "        \"Context human translation\",\n",
    "        ]]\n",
    "\n",
    "# select only the first 10 rows\n",
    "dfa = dfa.head(10)\n",
    "# dfa to csv\n",
    "dfa.to_csv('../test_dataframes/japanese_items/short_items.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an OpenAI ChatCompletion request with stream=True and stream_options={\"include_usage\": True}\n",
    "\n",
    "# a ChatCompletion request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Can you give me a summary of the pros and cons of the OpenAI API?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    # stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(f\"choices: {chunk.choices}\\nusage: {chunk.usage}\")\n",
    "    # print(f\"{chunk.content}\")\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Moritz is a great guy from Berlin\"},\n",
    "        # {'role': 'assistant', 'content': \"I don't know that\"},\n",
    "        {'role': 'user', 'content': \"who is Moritz?\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "# print the content of the response\n",
    "\n",
    "# for chunk in stream:\n",
    "#     if chunk.choices[0].delta.content is not None:\n",
    "#         print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# List of messages to be sent to the chat completion endpoint\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Always answer briefly. My name is Moritz! What is your name?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Guess where I likely come from, based on my name\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please sum up this dialogue\"},\n",
    "]\n",
    "\n",
    "# Create the chat completion stream\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # Assuming you're using the latest GPT-4 model\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Initialize an empty response container\n",
    "full_response = \"\"\n",
    "\n",
    "# Iterate over the stream and print each chunk\n",
    "for chunk in stream:\n",
    "    if 'choices' in chunk:\n",
    "        delta = chunk['choices'][0]['delta']\n",
    "        if 'content' in delta:\n",
    "            full_response += delta['content']\n",
    "            print(delta['content'], end=\"\")\n",
    "\n",
    "# Optionally, print the full response at the end\n",
    "print(\"\\n\\nFull Response:\\n\", full_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "client = OpenAI()\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create a streaming compion\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Always answer briefly. My name is Moritz! What is your name?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Guess where I likely come from, based on my name\"},\n",
    "            {\"role\": \"user\", \"content\": \"Please sum up this dialogue\"}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Print the streaming response\n",
    "    async for chunk in response:\n",
    "        if 'choices' in chunk:\n",
    "            choice = chunk['choices'][0]\n",
    "            if 'delta' in choice and 'content' in choice['delta']:\n",
    "                print(choice['delta']['content'], end=\"\")\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = Path(\"test_dataframes/italian_items/items_long.csv\")\n",
    "\n",
    "    # Load the csv file\n",
    "df = pd.read_csv(csv_file_path, delimiter='\\t')\n",
    "\n",
    "with open('config/column_names.yaml', 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        column_names = data['column_names']\n",
    "\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "# select the columns word and long_sentence\n",
    "\n",
    "df = df[['word', 'long_phrase']]\n",
    "df.to_csv('test_dataframes/italian_items/items_long_changed.csv', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.animal_type = \"Generic Animal\"\n",
    "\n",
    "    def make_sound(self):\n",
    "        print(f\"{self.animal_type} sound\")\n",
    "\n",
    "class Dog:\n",
    "    def __init__(self):\n",
    "        self.animal_sound = \"Woof!\"\n",
    "        self.animal = Animal()  # Create an Animal instance\n",
    "\n",
    "    def make_sound(self):\n",
    "        self.animal.make_sound()  # Call base class method directly\n",
    "        print(self.animal_sound)\n",
    "\n",
    "# Create objects and call methods\n",
    "animal = Animal()\n",
    "dog = Dog()\n",
    "\n",
    "animal.make_sound()  # Output: Generic Animal sound\n",
    "dog.make_sound()  # Output: Generic Animal sound\n",
    "                #        Woof!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.animal_type = \"Generic Animal\"\n",
    "\n",
    "    def make_sound(self):\n",
    "        print(f\"{self.animal_type} sound\")\n",
    "\n",
    "class Dog(Animal):\n",
    "    def make_sound(self):\n",
    "        self.animal_type = \"Dog\"  # Modify attribute before calling base class method\n",
    "        super().make_sound()\n",
    "        print(\"Woof!\")\n",
    "\n",
    "# Create objects and call methods\n",
    "animal = Animal()\n",
    "dog = Dog()\n",
    "\n",
    "animal.make_sound()  # Output: Generic Animal sound\n",
    "dog.make_sound()  # Output: Dog sound\n",
    "                #        Woof!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Markdown Table Example</title>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked@4.0.12/marked.min.js\"></script>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 40em;\n",
    "        }\n",
    "        table {\n",
    "            width: 50%;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "        }\n",
    "        th {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"markdown-content\"></div>\n",
    "\n",
    "    <script>\n",
    "        const markdownTable = `\n",
    "            | Name   | Age | Occupation   |\n",
    "            |--------|-----|--------------|\n",
    "            | John   | 25  | Engineer     |\n",
    "            | Alice  | 30  | Designer     |\n",
    "            | Bob    | 22  | Developer    |\n",
    "            `;\n",
    "\n",
    "        document.getElementById('markdown-content').innerHTML = marked.parse(markdownTable);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
