{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from config import client\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from config import column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# IDENTITY and PURPOSE\n",
       "\n",
       "You are a professional language teacher, dedicated to helping a student learn a language. Your task is to provide concise, relevant information for sentence-word Anki flashcards, ensuring the student can effectively study vocabulary. \n",
       "\n",
       "# TOOlS\n",
       "\n",
       "You rely mainly on your capability as LLM to predict the next string of characters. You don't need to analyse the table or anything. \n",
       "\n",
       "# INPUT:\n",
       "\n",
       "You will work with a table of sentence-word pairs from the Google extension 'LanguageReactor', containing the following columns:\n",
       "\n",
       "- 'Word'\n",
       "- 'Context'\n",
       "- 'Context machine translation'\n",
       "- ('Context human translation')\n",
       "\n",
       "The 'Context' column contains a sentence in the target language, that the student wants to learn. The 'Word' column contains one word that appears in the 'Context' sentence.\n",
       "\n",
       "# Steps\n",
       "\n",
       "1. ### Clean the data and check for parsing errors\n",
       "\n",
       "   Have a look at the table I provided you with. Don't use code for that, just rely on your prediction of characters as LLM.\n",
       "\n",
       "   - Remove furigana in brackets and correct weird formatting from 'Word' and 'Context'. However, pay attention that 'Word' always appears in 'Context'.\n",
       "   - check each row to ensure the 'Context' sentence is correctly parsed. The 'Word' should include the entire vocabulary word, not just a fragment. Pay particular attention to languages like Japanese, where parsers may miss the whole verb or expression. Also, check the 'Context machine translation' to see if the 'Word' makes sense in its 'Context'. If there is a parsing error and 'Word' is incomplete, adjust 'Word' to match the vocabulary in 'Context'. Ensure 'Word' is formatted exactly as it appears in 'Context' (including capitalization, grammar, punctuation, and spelling errors if present).\n",
       "\n",
       "2. ### Generate flashcard information\n",
       "\n",
       "   To assist the student, generate the following information for each row:\n",
       "\n",
       "   1. Two or more synonyms for 'Word' based on its 'Context'.\n",
       "   2. Two or more translations for 'Word' based on its 'Context'.\n",
       "   3. A simple 'Example sentence' using 'Word'.\n",
       "   4. The translation of the 'Example sentence'.\n",
       "   5. A brief explanation of 'Word' in its 'Context'.\n",
       "   6. A short explanation of the grammar.\n",
       "\n",
       "   When generating this information, stick to the following principles:\n",
       "\n",
       "   1. Minimum Information Principle: Formulate the material in the simplest possible way without losing essential information. Simplicity should not mean skipping difficult parts. That means you can safely leave out conjunctions like 'or', 'and' and you don't need to say: 現実 means 'reality' or 'actuality'. Instead just say: 現実: reality, actuality.\n",
       "   2. Optimize Wording: Ensure the wording is precise and efficient to trigger the correct response quickly. This will reduce errors, increase specificity, reduce response time, and enhance concentration.\n",
       "\n",
       "3. ### FURIGANA for EVERY JAPANESE word! THIS IS EXTREMELY IMPORTANT!\n",
       "\n",
       "   Add furigana in square brackets behind EACH kanji word and add a space before each kanji word The space before each kanji word is EXTREMELY important! Double check, – no – triple check that. Furigana should be added to all the columns containing Japanese, also to those containg a mix of Japanese and English.\n",
       "\n",
       "   - 私[わたし]は 大学生[だいがくせい]です。\n",
       "   - Attention: this would be wrong, as '事', '時間', '代' and '守' lack a blank space before. ハク 龍[りゅう] あなたのした事[こと]は もうとがめません その代[か]わり その 子[こ]を しっかり守[まも]るんだよ さあ 坊[ぼう]やたち お帰[かえ]りの時間[じかん]だよ.\n",
       "   - Same thing here, spaces missing before '代わり' and '行って': 私[わたし]の代[か]わりに行[い]ってください。\n",
       "\n",
       "4. ### Output\n",
       "\n",
       "   - Output the generated information as a Markdown table, including the column names as headers.\n",
       "   - Do not include warnings or notes in the output—only the requested sections.\n",
       "   - Do not include additional information like 'here is the markdown table' or anything else. The only thing I want to have is the markdown table.\n",
       "\n",
       "\n",
       "# EXAMPLES\n",
       "\n",
       "This is how the information you generate should look like:\n",
       "\n",
       "| Word       | Context                                                                                                                                                                 | Machine Translation                                                                                            | Synonyms                       | Translations        | Example sentence                             | Example sentence translation (German) | Explanation                                        |           Grammar explanation           | Additional Notes for chatGPT                                                                      |\n",
       "| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- | -------------------------------- | --------------------- | ---------------------------------------------- | --------------------------------------- | ---------------------------------------------------- | :---------------------------------------: | --------------------------------------------------------------------------------------------------- |\n",
       "| 子[こ]     | \"ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり 守[まも]るんだよ さあ 坊[ぼう]やたち お 帰[かえ]りの 時間[じかん]だよ\" | \"I won't do what you've done. Instead, we're going to protect that child. Come on, boy, it's time to go home.\" | 子ども[こども]、幼児[ようじ]   | child, kid          | その 子[こ]はかわいいです。                  | Das Kind ist süß.                   | child                                              |  子[こ] means \"child.\" Used as a noun.  | child is a simple word, don't make it complicated. Just give me the translation as 'Explanation'. |\n",
       "| 代[か]わり | \"ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり守るんだよ さあ 坊[ぼう]やたち お 帰[かえ]りの 時間[じかん]だよ\"        | \"I won't do what you've done. Instead, we're going to protect that child. Come on, boy, it's time to go home.\" | 代理[だいり]、替[か]わり       | instead, substitute | 彼[かれ]の 代[か]わりに 行[い]ってください。 | Gehen Sie bitte an seiner Stelle.     | instead, 'instead of doing ...'                    | 代わり means \"instead.\" Used as a noun. |                                                                                                   |\n",
       "| 事[こと]   | \"おばあちゃん ハク生きてた ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり 守[まも]るんだよ\"                            | \"Grandma, Haku was alive. I won't do what you've done. Instead, we're going to protect that child.\"            | 物事[ものごと]、事柄[ことがら] | thing, matter       | その 事[こと]は 難[むずか]しいです。         | Diese Sache ist schwierig.            | action, deed, 'your deeds'                         |   事 means \"thing\" or \"matter.\" Noun.   | '事' is a simple word, don't make it complicated. Just give me the translation as 'Explanation'.  |\n",
       "| 生[い]き   | \"グッドタイミングね おばあちゃん ハク生きてた ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません\"                                                                 | \"Good timing. Grandma, Haku was alive. I won't do what you've done.\"                                           | 生[い]きる、存在[そんざい]する | alive, living       | 彼[かれ]はまだ 生[い]きています。            | Er lebt noch.                         | 生きる: to live, u-verb, 生きて(い)た = was living |      生きる means \"to live.\" Verb.      | This is a verb                                                                                    |\n",
       "| タイミング | \"よかった グッドタイミングね おばあちゃん ハク生きてた\"                                                                                                                 | \"It was good Good timing. Grandma, Haku was alive.\"                                                            | 時期[じき]、機会[きかい]       | timing, opportunity | 今[いま]がいい タイミングです。              | Jetzt ist ein guter Zeitpunkt.        | 'Timing', English loanword                         |    タイミング means \"timing.\" Noun.    | Just give me the translation for the katakana, as this is a woard every english speaker knows.    |\n",
       "\n",
       "This is the table:\n",
       "\n",
       "Word\tContext\tContext machine translation\tContext human translation\n",
       "程度\t\"ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\n",
       "最小限つなぎ程度にして\n",
       "最後に塩と胡椒で味を整えてください\"\t\"But if you put too much in it, it tastes like mayonnaise.\n",
       "We're going to make sure that we have the least amount of connections.\n",
       "Finally, add some salt and pepper.\"\t\"But don't go overboard with it, or the mayonnaise will overpower the taste of eggs.\n",
       "Keep the mayonnaise to a minimum,\n",
       "and add salt and pepper to round out the flavors.\"\n",
       "最小限\t\"ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\n",
       "最小限つなぎ程度にして\n",
       "最後に塩と胡椒で味を整えてください\"\t\"But if you put too much in it, it tastes like mayonnaise.\n",
       "We're going to make sure that we have the least amount of connections.\n",
       "Finally, add some salt and pepper.\"\t\"But don't go overboard with it, or the mayonnaise will overpower the taste of eggs.\n",
       "Keep the mayonnaise to a minimum,\n",
       "and add salt and pepper to round out the flavors.\"\n",
       "刻ん\t\"さすがにまだ卵サンドは食べられないみたいだけど\n",
       "まずゆで卵を適度に刻んでください\n",
       "マヨネーズって何でも合いますよね\"\t\"I can't seem to eat an egg sandwich yet.\n",
       "First of all, you need to mark the eggs in moderation.\n",
       "I mean, mayonnaise is good for anything.\"\t\"But he hasn't had egg sandwiches since then.\n",
       "First, dice the boiled eggs.\n",
       "Mayonnaise goes well with everything.\"\n",
       "適度\t\"さすがにまだ卵サンドは食べられないみたいだけど\n",
       "まずゆで卵を適度に刻んでください\n",
       "マヨネーズって何でも合いますよね\"\t\"I can't seem to eat an egg sandwich yet.\n",
       "First of all, you need to mark the eggs in moderation.\n",
       "I mean, mayonnaise is good for anything.\"\t\"But he hasn't had egg sandwiches since then.\n",
       "First, dice the boiled eggs.\n",
       "Mayonnaise goes well with everything.\"\n",
       "さすが\t\"その後も毎日中島くんは新聞を配っている\n",
       "さすがにまだ卵サンドは食べられないみたいだけど\n",
       "まずゆで卵を適度に刻んでください\"\t\"Ever since then, I've been delivering newspapers every day.\n",
       "I can't seem to eat an egg sandwich yet.\n",
       "First of all, you need to mark the eggs in moderation.\"\t\"Nakajima still delivers the papers every day.\n",
       "But he hasn't had egg sandwiches since then.\n",
       "First, dice the boiled eggs.\"\n",
       "現実\t\"君が吐いた息を吸って後悔となってる\n",
       "現実は映画のようにはうまくいかない\n",
       "その後も毎日中島くんは新聞を配っている\"\t\"I'm breathing in your vomit, and now I regret it.\n",
       "Reality doesn't work like the movies.\n",
       "Ever since then, I've been delivering newspapers every day.\"\t\"MAINICHI SHINBUN\n",
       "Life isn't like the movies. Sometimes you don't get a happy ending.\n",
       "Nakajima still delivers the papers every day.\"\n",
       "浮かぶ\t\"君が吐いた白い息が今ゆっくり風に乗って\n",
       "空に浮かぶ雲の中に少しずつ消えてゆく\n",
       "遠く高い空の中で手を伸ばす白い雲\"\t\"The white breath you spewed is now moving slowly in the wind.\n",
       "It disappears into the clouds.\n",
       "White clouds reaching high into the sky.\"\n",
       "吐い\t\"自分が本気で惚れた女 安く見るもんじゃないよ\n",
       "君が吐いた白い息が今ゆっくり風に乗って\n",
       "空に浮かぶ雲の中に少しずつ消えてゆく\"\t\"I'm not looking for a woman that I really love.\n",
       "The white breath you spewed is now moving slowly in the wind.\n",
       "It disappears into the clouds.\"\n",
       "本気\t\"誇りに思っていいんじゃないのかい\n",
       "自分が本気で惚れた女 安く見るもんじゃないよ\n",
       "君が吐いた白い息が今ゆっくり風に乗って\"\t\"I don't think you should be proud.\n",
       "I'm not looking for a woman that I really love.\n",
       "The white breath you spewed is now moving slowly in the wind.\"\t\"You should be honored that she fell in love with you.\n",
       "You loved her too, didn't you? Don't insult her by saying you didn't deserve her.\n",
       "\"\n",
       "誇り\t\"そんな女に惚れられたってこと\n",
       "誇りに思っていいんじゃないのかい\n",
       "自分が本気で惚れた女 安く見るもんじゃないよ\"\t\"I mean, he fell in love with her.\n",
       "I don't think you should be proud.\n",
       "I'm not looking for a woman that I really love.\"\t\"She didn't have to, but she did it anyway.\n",
       "You should be honored that she fell in love with you.\n",
       "You loved her too, didn't you? Don't insult her by saying you didn't deserve her.\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "# IDENTITY and PURPOSE\n",
       "\n",
       "You function as a japanese parser. You're main purpose is to provide furigana for japanese texts, in square brackets [] behind each kanji word and a blank space before each kanji word. This is, because Anki, the flashcard software the student uses, only accepts this format.\n",
       "\n",
       "# INPUT\n",
       "\n",
       "- a table with information that the student needs to study vocabulary\n",
       "\n",
       "# Steps\n",
       "\n",
       "1. ### Add FURIGANA for EVERY JAPANESE word! THIS IS EXTREMELY IMPORTANT!\n",
       "\n",
       "   Add furigana in square brackets behind EACH kanji word and add a space before each kanji word The space before each kanji word is EXTREMELY important! Double check, – no – triple check that. Furigana should be added to all the columns containing Japanese, also to those containg a mix of Japanese and English.\n",
       "\n",
       "\n",
       "   - 私[わたし]は 大学生[だいがくせい]です。\n",
       "   - Attention: this would be wrong, as '事', '時間', '代' and '守' lack a blank space before. ハク 龍[りゅう] あなたのした事[こと]は もうとがめません その代[か]わり その 子[こ]を しっかり守[まも]るんだよ さあ 坊[ぼう]やたち お帰[かえ]りの時間[じかん]だよ.\n",
       "   - Same thing here, spaces missing before '代わり' and '行って': 私[わたし]の代[か]わりに行[い]ってください。\n",
       "2. ### Output\n",
       "\n",
       "\n",
       "   - Output the generated information as a Markdown table, including the column names as headers.\n",
       "   - Do not include warnings or notes in the output—only the requested sections.\n",
       "   - Do not include additional information like 'here is the markdown table' or anything else. The only thing I want to have is the markdown table.\n",
       "\n",
       "# EXAMPLES\n",
       "\n",
       "Here are some examples of how you should add the furigana!\n",
       "\n",
       "| Word       | Context                                                                                                                                                                 |                                                                                                                | Synonyms                       | Example sentence                             | Explanation                                                |            Grammar explanation            |\n",
       "| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- | ------------------------------ | -------------------------------------------- | ---------------------------------------------------------- | :---------------------------------------: |\n",
       "| 子[こ]     | \"ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり 守[まも]るんだよ さあ 坊[ぼう]やたち お 帰[かえ]りの 時間[じかん]だよ\" | \"I won't do what you've done. Instead, we're going to protect that child. Come on, boy, it's time to go home.\" | 子ども[こども]、幼児[ようじ]   | その 子[こ]はかわいいです。                  | child                                                      |   子[こ] means \"child.\" Used as a noun.   |\n",
       "| 代[か]わり | \"ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり守るんだよ さあ 坊[ぼう]やたち お 帰[かえ]りの 時間[じかん]だよ\"        | \"I won't do what you've done. Instead, we're going to protect that child. Come on, boy, it's time to go home.\" | 代理[だいり]、替[か]わり       | 彼[かれ]の 代[か]わりに 行[い]ってください。 | instead, 'instead of doing ...'                            |  代わり means \"instead.\" Used as a noun.  |\n",
       "| 事[こと]   | \"おばあちゃん ハク生きてた ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません その 代[か]わり その 子[こ]を しっかり 守[まも]るんだよ\"                            | \"Grandma, Haku was alive. I won't do what you've done. Instead, we're going to protect that child.\"            | 物事[ものごと]、事柄[ことがら] | その 事[こと]は 難[むずか]しいです。         | action, deed, 'your deeds'                                 | 事[こと] means \"thing\" or \"matter.\" Noun. |\n",
       "| 生[い]き   | \"グッドタイミングね おばあちゃん ハク生きてた ハク 龍[りゅう] あなたのした 事[こと]は もうとがめません\"                                                                 | \"Good timing. Grandma, Haku was alive. I won't do what you've done.\"                                           | 生[い]きる、存在[そんざい]する | 彼[かれ]はまだ 生[い]きています。            | 生[い]きる: to live, u-verb, 生[い]きて(い)た = was living |     生[い]きる means \"to live.\" Verb.     |\n",
       "| タイミング | \"よかった グッドタイミングね おばあちゃん ハク生[い]きてた\"                                                                                                             | \"It was good Good timing. Grandma, Haku was alive.\"                                                            | 時期[じき]、機会[きかい]       | 今[いま]がいい タイミングです。              | 'Timing', English loanword                                 |     タイミング means \"timing.\" Noun.     |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load markdown from github repository https://github.com/moritzvitt/moritzProjekt/blob/markdown/system_japanese.md\n",
    "class BaseAnkiDeckGenerator:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.ai_input_df = self.df[['short_phrase', 'short_translation', 'word']]\n",
    "\n",
    "\n",
    "    # @log_io\n",
    "\n",
    "def load_markdown():\n",
    "    url1 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/system_japanese.md\"\n",
    "    url2 = \"https://raw.githubusercontent.com/moritzvitt/moritzProjekt/markdown/add_furigana.md\"\n",
    "    \n",
    "    response1 = requests.get(url1)\n",
    "    markdown1 = response1.text\n",
    "\n",
    "    response2 = requests.get(url2)\n",
    "    markdown2 = response2.text\n",
    "\n",
    "    merged_markdown = markdown1 + \"\\n\" + markdown2\n",
    "    return merged_markdown\n",
    "\n",
    "# load csv from test_dataframes \n",
    "\n",
    "# load dataframe from csv\n",
    "df = pd.read_csv('../test_dataframes/japanese_items/short_items.csv', delimiter='\\t', encoding='utf-8')\n",
    "# print(df.head())\n",
    "# print(df.shape)\n",
    "# # load column_names from config.py\n",
    "# df.columns = column_names\n",
    "\n",
    "# dfa = df[[\n",
    "#         \"Word\", \n",
    "#         \"Context\",\n",
    "#         \"Context machine translation\",\n",
    "#         \"Context human translation\",\n",
    "#         ]]\n",
    "\n",
    "# # select only the first 10 rows\n",
    "# dfa = dfa.head(10)\n",
    "# # dfa to csv\n",
    "# dfa.to_csv('../test_dataframes/japanese_items/short_items.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "    \n",
    "\n",
    "# run \n",
    "def run():\n",
    "    markdown = load_markdown()\n",
    "    display(Markdown(markdown))\n",
    "    # also safe the markdown to a new file\n",
    "    with open(\"moin.md\", \"w\") as file:\n",
    "        file.write(markdown + df.to_markdown())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WORD|胡椒|ja  Word        最後に塩と胡椒で味を整えてください  \\\n",
      "0   WORD|程度|ja  Word              最小限つなぎ程度にして   \n",
      "1  WORD|最小限|ja  Word              最小限つなぎ程度にして   \n",
      "2   WORD|刻む|ja  Word         まずゆで卵を適度に刻んでください   \n",
      "3   WORD|適度|ja  Word         まずゆで卵を適度に刻んでください   \n",
      "4  WORD|さすが|ja  Word  さすがにまだ卵サンドは食べられないみたいだけど   \n",
      "\n",
      "                  Finally, add some salt and pepper.   胡椒 胡椒.1  Noun  \\\n",
      "0  We're going to make sure that we have the leas...   程度   程度  Noun   \n",
      "1  We're going to make sure that we have the leas...  最小限  最小限  Noun   \n",
      "2  First of all, you need to mark the eggs in mod...   刻ん   刻む  Verb   \n",
      "3  First of all, you need to mark the eggs in mod...   適度   適度  Noun   \n",
      "4           I can't seem to eat an egg sandwich yet.  さすが  さすが   Adv   \n",
      "\n",
      "   Unnamed: 7                         pepper, black pepper  Netflix  ...  216  \\\n",
      "0         NaN                       degree, extent, amount  Netflix  ...  215   \n",
      "1         NaN  minimum, minimum limit, minimum requirement  Netflix  ...  215   \n",
      "2         NaN                      carved, engrave, minced  Netflix  ...  212   \n",
      "3         NaN              moderate, appropriate, suitable  Netflix  ...  212   \n",
      "4         NaN       As expected, indeed, Just as I thought  Netflix  ...  211   \n",
      "\n",
      "   80113548  Midnight Diner E7 Episode 7  2024-05-17 15:11  \\\n",
      "0  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "1  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "2  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "3  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:10   \n",
      "4  80113548  Midnight Diner E7 Episode 7  2024-05-17 15:09   \n",
      "\n",
      "      最小限つなぎ程度にして\\n最後に塩と胡椒で味を整えてください\\nあ まずあの 僕あのこっちで  \\\n",
      "0  ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\\n最小限つなぎ程度にして\\n最...   \n",
      "1  ただし入れすぎると卵の味よりマヨネーズの味が勝ってしまうので\\n最小限つなぎ程度にして\\n最...   \n",
      "2  さすがにまだ卵サンドは食べられないみたいだけど\\nまずゆで卵を適度に刻んでください\\nマヨネ...   \n",
      "3  さすがにまだ卵サンドは食べられないみたいだけど\\nまずゆで卵を適度に刻んでください\\nマヨネ...   \n",
      "4  その後も毎日中島くんは新聞を配っている\\nさすがにまだ卵サンドは食べられないみたいだけど\\n...   \n",
      "\n",
      "   We're going to make sure that we have the least amount of connections.\\nFinally, add some salt and pepper.\\nOh, first of all, I'm over there.  \\\n",
      "0  But if you put too much in it, it tastes like ...                                                                                               \n",
      "1  But if you put too much in it, it tastes like ...                                                                                               \n",
      "2  I can't seem to eat an egg sandwich yet.\\nFirs...                                                                                               \n",
      "3  I can't seem to eat an egg sandwich yet.\\nFirs...                                                                                               \n",
      "4  Ever since then, I've been delivering newspape...                                                                                               \n",
      "\n",
      "  Keep the mayonnaise to a minimum,\\nand add salt and pepper to round out the flavors.\\nMaster. I brought my own bread.  \\\n",
      "0  But don't go overboard with it, or the mayonna...                                                                      \n",
      "1  But don't go overboard with it, or the mayonna...                                                                      \n",
      "2  But he hasn't had egg sandwiches since then.\\n...                                                                      \n",
      "3  But he hasn't had egg sandwiches since then.\\n...                                                                      \n",
      "4  Nakajima still delivers the papers every day.\\...                                                                      \n",
      "\n",
      "   1715958665910_prev.jpg  1715958665910_next.jpg  1715958665910.mp3  \n",
      "0  1715958659411_prev.jpg  1715958659411_next.jpg  1715958659411.mp3  \n",
      "1  1715958656851_prev.jpg  1715958656851_next.jpg  1715958656851.mp3  \n",
      "2  1715958621198_prev.jpg  1715958621198_next.jpg  1715958621198.mp3  \n",
      "3  1715958619583_prev.jpg  1715958619583_next.jpg  1715958619583.mp3  \n",
      "4  1715958582029_prev.jpg  1715958582029_next.jpg  1715958582029.mp3  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "(419, 24)\n"
     ]
    }
   ],
   "source": [
    "# load dataframe from csv\n",
    "df = pd.read_csv('../test_dataframes/japanese_items/items.csv', delimiter='\\t', encoding='utf-8')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "# load column_names from config.py\n",
    "df.columns = column_names\n",
    "\n",
    "dfa = df[[\n",
    "        \"Word\", \n",
    "        \"Context\",\n",
    "        \"Context machine translation\",\n",
    "        \"Context human translation\",\n",
    "        ]]\n",
    "\n",
    "# select only the first 10 rows\n",
    "dfa = dfa.head(10)\n",
    "# dfa to csv\n",
    "dfa.to_csv('../test_dataframes/japanese_items/short_items.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choices: [Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)]\n",
      "usage: None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatCompletionChunk' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/pydantic/main.py:759\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpydantic_extra\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;241m.\u001b[39mchoices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124musage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;241m.\u001b[39musage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m****************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/pydantic/main.py:761\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pydantic_extra[item]\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 761\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, item):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatCompletionChunk' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "# Example of an OpenAI ChatCompletion request with stream=True and stream_options={\"include_usage\": True}\n",
    "\n",
    "# a ChatCompletion request\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Can you give me a summary of the pros and cons of the OpenAI API?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    # stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(f\"choices: {chunk.choices}\\nusage: {chunk.usage}\")\n",
    "    # print(f\"{chunk.content}\")\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='Mor', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='itz', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' could', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' refer', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' many', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' individuals', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' as', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' it', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' is', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' common', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' name', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' in', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' German', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='-speaking', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' countries', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' Without', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' additional', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' context', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=\" it's\", function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' difficult', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' determine', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' exactly', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' which', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' Mor', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='itz', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' are', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' referring', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' If', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' have', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' more', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' specific', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' information', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' about', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' Mor', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='itz', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' such', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' as', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' his', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' last', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' name', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' profession', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' any', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' notable', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' achievements', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' could', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' provide', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' more', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' detailed', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=' answer', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=None)\n",
      "ChatCompletionChunk(id='chatcmpl-9VIXMqyH2Vcb1bayBfZID39Crmnx7', choices=[], created=1717246452, model='gpt-4o-2024-05-13', object='chat.completion.chunk', system_fingerprint='fp_319be4768e', usage=CompletionUsage(completion_tokens=67, prompt_tokens=24, total_tokens=91))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"Moritz is a great guy from Berlin\"},\n",
    "        # {'role': 'assistant', 'content': \"I don't know that\"},\n",
    "        {'role': 'user', 'content': \"who is Moritz?\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    ")\n",
    "\n",
    "# print the content of the response\n",
    "\n",
    "# for chunk in stream:\n",
    "#     if chunk.choices[0].delta.content is not None:\n",
    "#         print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Full Response:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# List of messages to be sent to the chat completion endpoint\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Always answer briefly. My name is Moritz! What is your name?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Guess where I likely come from, based on my name\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please sum up this dialogue\"},\n",
    "]\n",
    "\n",
    "# Create the chat completion stream\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # Assuming you're using the latest GPT-4 model\n",
    "    messages=messages,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Initialize an empty response container\n",
    "full_response = \"\"\n",
    "\n",
    "# Iterate over the stream and print each chunk\n",
    "for chunk in stream:\n",
    "    if 'choices' in chunk:\n",
    "        delta = chunk['choices'][0]['delta']\n",
    "        if 'content' in delta:\n",
    "            full_response += delta['content']\n",
    "            print(delta['content'], end=\"\")\n",
    "\n",
    "# Optionally, print the full response at the end\n",
    "print(\"\\n\\nFull Response:\\n\", full_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object Stream can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(choice[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/src/LR2Anki/venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Create a streaming compion\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     16\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     18\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlways answer briefly. My name is Moritz! What is your name?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     19\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuess where I likely come from, based on my name\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     20\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease sum up this dialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     21\u001b[0m         ],\n\u001b[1;32m     22\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Print the streaming response\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[0;31mTypeError\u001b[0m: object Stream can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "client = OpenAI()\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create a streaming compion\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Always answer briefly. My name is Moritz! What is your name?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Guess where I likely come from, based on my name\"},\n",
    "            {\"role\": \"user\", \"content\": \"Please sum up this dialogue\"}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Print the streaming response\n",
    "    async for chunk in response:\n",
    "        if 'choices' in chunk:\n",
    "            choice = chunk['choices'][0]\n",
    "            if 'delta' in choice and 'content' in choice['delta']:\n",
    "                print(choice['delta']['content'], end=\"\")\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = Path(\"test_dataframes/italian_items/items_long.csv\")\n",
    "\n",
    "    # Load the csv file\n",
    "df = pd.read_csv(csv_file_path, delimiter='\\t')\n",
    "\n",
    "with open('config/column_names.yaml', 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "        column_names = data['column_names']\n",
    "\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "# select the columns word and long_sentence\n",
    "\n",
    "df = df[['word', 'long_phrase']]\n",
    "df.to_csv('test_dataframes/italian_items/items_long_changed.csv', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic Animal sound\n",
      "Generic Animal sound\n",
      "Woof!\n"
     ]
    }
   ],
   "source": [
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.animal_type = \"Generic Animal\"\n",
    "\n",
    "    def make_sound(self):\n",
    "        print(f\"{self.animal_type} sound\")\n",
    "\n",
    "class Dog:\n",
    "    def __init__(self):\n",
    "        self.animal_sound = \"Woof!\"\n",
    "        self.animal = Animal()  # Create an Animal instance\n",
    "\n",
    "    def make_sound(self):\n",
    "        self.animal.make_sound()  # Call base class method directly\n",
    "        print(self.animal_sound)\n",
    "\n",
    "# Create objects and call methods\n",
    "animal = Animal()\n",
    "dog = Dog()\n",
    "\n",
    "animal.make_sound()  # Output: Generic Animal sound\n",
    "dog.make_sound()  # Output: Generic Animal sound\n",
    "                #        Woof!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic Animal sound\n",
      "Dog sound\n",
      "Woof!\n"
     ]
    }
   ],
   "source": [
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.animal_type = \"Generic Animal\"\n",
    "\n",
    "    def make_sound(self):\n",
    "        print(f\"{self.animal_type} sound\")\n",
    "\n",
    "class Dog(Animal):\n",
    "    def make_sound(self):\n",
    "        self.animal_type = \"Dog\"  # Modify attribute before calling base class method\n",
    "        super().make_sound()\n",
    "        print(\"Woof!\")\n",
    "\n",
    "# Create objects and call methods\n",
    "animal = Animal()\n",
    "dog = Dog()\n",
    "\n",
    "animal.make_sound()  # Output: Generic Animal sound\n",
    "dog.make_sound()  # Output: Dog sound\n",
    "                #        Woof!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3130921398.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    border: 1px solid #dddddd;\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Markdown Table Example</title>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/marked@4.0.12/marked.min.js\"></script>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 40em;\n",
    "        }\n",
    "        table {\n",
    "            width: 50%;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "        }\n",
    "        th {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"markdown-content\"></div>\n",
    "\n",
    "    <script>\n",
    "        const markdownTable = `\n",
    "            | Name   | Age | Occupation   |\n",
    "            |--------|-----|--------------|\n",
    "            | John   | 25  | Engineer     |\n",
    "            | Alice  | 30  | Designer     |\n",
    "            | Bob    | 22  | Developer    |\n",
    "            `;\n",
    "\n",
    "        document.getElementById('markdown-content').innerHTML = marked.parse(markdownTable);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
