{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown complete!          gg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "    print(f\"\\rCountdown: {i} seconds remaining\", end=\"\")\n",
    "    time.sleep(1)  # Sleep for 1 second to visually see the countdown\n",
    "print(\"\\rCountdown complete!          \")  # Overwrite with final message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m π \u001b[38;5;241m=\u001b[39m pi\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pi\n\u001b[0;32m----> 3\u001b[0m area \u001b[38;5;241m=\u001b[39m π \u001b[38;5;241m*\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m résumé \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknows Python\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m résumé\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "π = pi\n",
    "from math import pi\n",
    "area = π * r**2\n",
    "\n",
    "résumé = 'knows Python'\n",
    "'Python' in résumé\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied template to df; created df_messages.\n",
      "Filtered fields based on config.json\n",
      "schoolyard, playground\n",
      "Schulhof: Schoolyard, an outdoor area within a school where students can socialize.\n",
      "\n",
      "- Immer: always, adverb \n",
      "- schön: nice, adjective \n",
      "- aufpassen: to pay attention, verb, imperative, singular\n",
      "- dass: that, conjunction\n",
      "- die Kids: Kids, definitive article ('the'), noun, plural\n",
      "- nicht: not, adverb, negation\n",
      "- auf: on, preposition\n",
      "- dem Schulhof: 'dem' definite article, dative, masculine noun (der Schulhof = the schoolyard)\n",
      "- rauchen: smoke, verb, 3rd person plural, present tense. <br>\n",
      "Children, youngsters\n",
      "Kids: young people or children.\n",
      "\n",
      "- Immer: always, adverb<br>\n",
      "- schön: nicely, adverb modifying 'aufpassen'<br>\n",
      "- aufpassen: to watch out, verb, infinitive<br>\n",
      "- dass: that, subordinating conjunction<br>\n",
      "- die Kids: 'kids', definite article, plural, nominative case<br>\n",
      "- nicht: not, adverb of negation<br>\n",
      "- auf dem Schulhof: 'on the schoolyard', prepositional phrase, dative case ('dem' is definite article)<br>\n",
      "- rauchen: to smoke, verb, infinitive\n",
      "Secondary School, Senior High\n",
      "Highschool: An educational institution for adolescents; represents teenage rebellion in song.\n",
      "\n",
      " df.columns Index(['ID', 'word_or_phrase', 'short_phrase', 'short_translation', 'word',\n",
      "       'stem', 'word_type', 'NAN', 'word_translation', 'website', 'language',\n",
      "       'translation_language', 'romaji', 'long_romaji', 'time_stamp',\n",
      "       'movie_code', 'source', 'date', 'long_phrase', 'machine_translation',\n",
      "       'human_translation', 'first_jpg', 'second_jpg', 'audio',\n",
      "       'native_language', 'synonyms', 'long_test_message'],\n",
      "      dtype='object') \n",
      "\n",
      "{{c1::Schulhof::schoolyard, playground}}\n",
      "Immer schön aufpassen, dass die Kids nicht auf dem {{c1::Schulhof::schoolyard, playground}} rauchen.\n",
      "Hallo, mein Schatz. - Na, mein Rocker?\n",
      "{{c1::Kids::Children, youngsters}}\n",
      "Immer schön aufpassen, dass die {{c1::Kids::Children, youngsters}} nicht auf dem Schulhof rauchen.\n",
      "Hallo, mein Schatz. - Na, mein Rocker?\n",
      "{{c1::Highschool::Secondary School, Senior High}}\n",
      "Immer schön aufpassen, dass die Kids nicht auf dem Schulhof rauchen.\n",
      "Index(['ID', 'word_or_phrase', 'short_phrase', 'short_translation', 'word',\n",
      "       'stem', 'word_type', 'NAN', 'word_translation', 'website', 'language',\n",
      "       'translation_language', 'romaji', 'long_romaji', 'time_stamp',\n",
      "       'movie_code', 'source', 'date', 'long_phrase', 'machine_translation',\n",
      "       'human_translation', 'first_jpg', 'second_jpg', 'audio',\n",
      "       'native_language', 'synonyms', 'long_test_message', 'explanation',\n",
      "       'first_example', 'second_example', 'hint', 'definition', 'grammar',\n",
      "       'conjugation', 'image', 'cloze'],\n",
      "      dtype='object')\n",
      "{{c1::Schulhof::schoolyard, playground}}\n",
      "Immer schön aufpassen, dass die Kids nicht auf dem {{c1::Schulhof::schoolyard, playground}} rauchen.\n",
      "Hallo, mein Schatz. - Na, mein Rocker?\n",
      "{{c1::Kids::Children, youngsters}}\n",
      "Immer schön aufpassen, dass die {{c1::Kids::Children, youngsters}} nicht auf dem Schulhof rauchen.\n",
      "Hallo, mein Schatz. - Na, mein Rocker?\n",
      "{{c1::Highschool::Secondary School, Senior High}}\n",
      "Immer schön aufpassen, dass die Kids nicht auf dem Schulhof rauchen.\n",
      "Anki package \"/Users/moritzvitt/Desktop/japanese2english_LLN.apkg\" has been created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dy/67d_dwt15t93yftrvlycwhm40000gn/T/ipykernel_6050/3132165822.py:74: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace('', np.nan)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import functions from other scripts \n",
    "from formatting import general_formatting, definition_field, notes_field\n",
    "from furigana import add_furigana\n",
    "from deck import generate_anki_deck\n",
    "from gpt import create_df_messages, generate_content\n",
    "\n",
    "# Load the environment variables\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key\n",
    "\n",
    "def main(df, config_json):\n",
    "\n",
    "    # drop all rows where word_or_phrase is phrase\n",
    "    df = df[df['word_or_phrase'] != 'Phrase']\n",
    "    # print(\"\\nCOLUMNS\", df.columns, \"\\n\")\n",
    "    df_messages = create_df_messages(df, config_json)\n",
    "    # print the columns from df_messages\n",
    "    # print(\"\\nCOLUMNS\", df_messages.columns, \"\\n\")\n",
    "\n",
    "    error_count = 0\n",
    "    rows_to_delete = []  # List to store the indices of rows to be deleted\n",
    "\n",
    "\n",
    "\n",
    "    for idx, row in df_messages.iterrows():\n",
    "        for column in df_messages.columns:\n",
    "            try:\n",
    "                df.at[idx, column] = generate_content(row[column])\n",
    "                error_count = 0  # Reset error count on success\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                if error_count >= 3:\n",
    "                    rows_to_delete.append(idx)  # Add the index of the current row to the list\n",
    "                    print(\"encountered 3 errors, skipping row...\")\n",
    "                    return  # Exit the inner loop to move to the next row\n",
    "\n",
    "    # if error_count < 3:  # Check for overall success after the loop\n",
    "    #     # Delete the rows from the DataFrame\n",
    "\n",
    "    print(\"\\n df.columns\", df.columns, \"\\n\")\n",
    "    df = df.drop(rows_to_delete)\n",
    "    general_formatting(df, config_json)\n",
    "\n",
    "\n",
    "    print(df.columns)\n",
    "    # Apply formatting functions, general formatting: adding fields (so that the df is processed correctly), cloze pattern, hint, id, mp3, image\n",
    "    general_formatting(df, config_json)\n",
    "\n",
    "    # apply the other formatting for definition and notes field\n",
    "    df[\"notes\"] = df.apply(lambda row: notes_field(row[\"human_translation\"], row[\"word_translation\"]), axis=1)\n",
    "    df[\"definition\"] = df.apply(lambda row: definition_field(row[\"definition\"], row[\"explanation\"], row[\"grammar\"], row[\"conjugation\"], row[\"first_example\"], row[\"second_example\"]), axis=1)\n",
    "\n",
    "    df = df.map(lambda x: add_furigana(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Generate Anki deck\n",
    "    package = generate_anki_deck(df)  # Ensure this function accepts the dataframe and processes it accordingly\n",
    "\n",
    "    # save the deck to desktop\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    package_path = os.path.join(desktop_path, f'{config_json[\"language\"]}2{config_json[\"native_language\"]}_LLN.apkg')\n",
    "    package.write_to_file(package_path)\n",
    "\n",
    "    print(f'Anki package \"{package_path}\" has been created.')\n",
    "\n",
    "    # only keep the created fields, that should be displayed on the index.html\n",
    "    # df = df[[\"synonyms\", \"hint\", \"first_example\", \"second_example\", \"explanation\", \"cloze\", \"definition\", \"image\", \"audio\"]]\n",
    "    df = df[[\"synonyms\", \"hint\", \"first_example\", \"second_example\", \"explanation\", \"cloze\", \"definition\"]]\n",
    "    # Replace empty strings with NaN\n",
    "    df = df.replace('', np.nan)\n",
    "    # Drop columns that only contain NaN\n",
    "    df = df.dropna(how='all', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    json_file_path = '/Users/moritzvitt/LR2Anki/config/jn_config.json'\n",
    "    csv_file_path = '/Users/moritzvitt/LR2Anki/test_dataframes/ger_items.csv'\n",
    "\n",
    "    # Open the JSON file and load its contents into a Python dictionary\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        config_json = json.load(json_file)\n",
    "    \n",
    "    column_names = config_json['column_names']\n",
    "    df = pd.read_csv(csv_file_path, delimiter='\\t', names=column_names)\n",
    "    # native_language column\n",
    "    df['native_language'] = config_json['native_language']\n",
    "    main(df, config_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
